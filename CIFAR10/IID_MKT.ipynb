{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "import pickle\n",
    "import time\n",
    "from torch.utils.data import ConcatDataset, Dataset, Subset\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [5, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CIFAR10('D:/downloads/btp/outputforpaper/CIFAR10', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = CIFAR10('D:/downloads/btp/outputforpaper/CIFAR10', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_size = len(train_dataset)\n",
    "total_test_size = len(test_dataset)\n",
    "classes = 10\n",
    "input_dim = 784\n",
    "num_clients = 25\n",
    "rounds = 30\n",
    "batch_size = 32\n",
    "in_group_rounds=3\n",
    "epochs_per_client =10\n",
    "learning_rate = 8e-2\n",
    "num_malicious_clients=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader(DataLoader):\n",
    "        def __init__(self, dl, device):\n",
    "            self.dl = dl\n",
    "            self.device = device\n",
    "\n",
    "        def __iter__(self):\n",
    "            for batch in self.dl:\n",
    "                yield to_device(batch, self.device)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.dl)\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "\n",
    "def average_models(new_model, next, scale):\n",
    "    if new_model == None:\n",
    "        new_model = next\n",
    "        for key in new_model:\n",
    "            new_model[key] = new_model[key] * scale\n",
    "    else:\n",
    "        for key in new_model:\n",
    "            new_model[key] = new_model[key] + (next[key] * scale)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FederatedNet(torch.nn.Module):    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Update input channels to 3 for RGB images\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 16, kernel_size=5, padding=2),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2))\n",
    "        \n",
    "        self.fc = torch.nn.Linear(8 * 8 * 32, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    def batch_accuracy(self, outputs, labels):\n",
    "        with torch.no_grad():\n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "            return torch.tensor(torch.sum(predictions == labels).item() / len(predictions))\n",
    "    \n",
    "    def _process_batch(self, batch):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        accuracy = self.batch_accuracy(outputs, labels)\n",
    "        return (loss, accuracy)\n",
    "    \n",
    "    def fit(self, dataset, epochs, lr, batch_size=128, opt=torch.optim.SGD):\n",
    "        dataloader = DeviceDataLoader(DataLoader(dataset, batch_size, shuffle=True), device)\n",
    "        optimizer = opt(self.parameters(), lr)\n",
    "        history = []\n",
    "        for epoch in range(epochs):\n",
    "            losses = []\n",
    "            accs = []\n",
    "            for batch in dataloader:\n",
    "                loss, acc = self._process_batch(batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                loss.detach()\n",
    "                losses.append(loss)\n",
    "                accs.append(acc)\n",
    "            avg_loss = torch.stack(losses).mean().item()\n",
    "            avg_acc = torch.stack(accs).mean().item()\n",
    "            history.append((avg_loss, avg_acc))\n",
    "        return history\n",
    "    \n",
    "    def evaluate(self, dataset, batch_size=128):\n",
    "        dataloader = DeviceDataLoader(DataLoader(dataset, batch_size), device)\n",
    "        losses = []\n",
    "        accs = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                loss, acc = self._process_batch(batch)\n",
    "                losses.append(loss)\n",
    "                accs.append(acc)\n",
    "        avg_loss = torch.stack(losses).mean().item()\n",
    "        avg_acc = torch.stack(accs).mean().item()\n",
    "        return (avg_loss, avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_per_client = total_train_size // num_clients\n",
    "client_datasets = random_split(train_dataset, [min(i + examples_per_client, \n",
    "           total_train_size) - i for i in range(0, total_train_size, examples_per_client)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, client_id, dataset):\n",
    "        self.client_id = client_id\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def get_dataset_size(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def get_client_id(self):\n",
    "        return self.client_id\n",
    "    \n",
    "    def train(self, parameters_dict):\n",
    "        net = to_device(FederatedNet(), device)\n",
    "        net.load_state_dict(parameters_dict)\n",
    "        train_history = net.fit(self.dataset, epochs_per_client, learning_rate, batch_size)\n",
    "        return net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = [Client('client_' + str(i), client_datasets[i]) for i in range(num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After round 1, train_loss = 1.5604, dev_loss = 1.5647, dev_acc = 0.4404\n",
      "\n",
      "After round 2, train_loss = 1.1465, dev_loss = 1.2095, dev_acc = 0.6042\n",
      "\n",
      "After round 3, train_loss = 1.0759, dev_loss = 1.1922, dev_acc = 0.6427\n",
      "\n",
      "After round 4, train_loss = 1.0352, dev_loss = 1.2016, dev_acc = 0.6632\n",
      "\n",
      "After round 5, train_loss = 0.9915, dev_loss = 1.1957, dev_acc = 0.6747\n",
      "\n",
      "After round 6, train_loss = 0.9535, dev_loss = 1.1914, dev_acc = 0.6767\n",
      "\n",
      "After round 7, train_loss = 0.9242, dev_loss = 1.1887, dev_acc = 0.6836\n",
      "\n",
      "After round 8, train_loss = 0.9032, dev_loss = 1.1936, dev_acc = 0.6882\n",
      "\n",
      "After round 9, train_loss = 0.8746, dev_loss = 1.1886, dev_acc = 0.6916\n",
      "\n",
      "After round 10, train_loss = 0.8535, dev_loss = 1.1902, dev_acc = 0.6938\n",
      "\n",
      "After round 11, train_loss = 0.8345, dev_loss = 1.1929, dev_acc = 0.6931\n",
      "\n",
      "After round 12, train_loss = 0.8146, dev_loss = 1.1912, dev_acc = 0.6959\n",
      "\n",
      "After round 13, train_loss = 0.797, dev_loss = 1.1894, dev_acc = 0.6978\n",
      "\n",
      "After round 14, train_loss = 0.7836, dev_loss = 1.1947, dev_acc = 0.6999\n",
      "\n",
      "After round 15, train_loss = 0.7703, dev_loss = 1.1967, dev_acc = 0.7001\n",
      "\n",
      "After round 16, train_loss = 0.7573, dev_loss = 1.1974, dev_acc = 0.701\n",
      "\n",
      "After round 17, train_loss = 0.7468, dev_loss = 1.2032, dev_acc = 0.704\n",
      "\n",
      "After round 18, train_loss = 0.731, dev_loss = 1.2004, dev_acc = 0.7035\n",
      "\n",
      "After round 19, train_loss = 0.7208, dev_loss = 1.2004, dev_acc = 0.7052\n",
      "\n",
      "After round 20, train_loss = 0.7146, dev_loss = 1.2059, dev_acc = 0.7049\n",
      "\n",
      "After round 21, train_loss = 0.7037, dev_loss = 1.208, dev_acc = 0.707\n",
      "\n",
      "After round 22, train_loss = 0.6949, dev_loss = 1.2122, dev_acc = 0.7081\n",
      "\n",
      "After round 23, train_loss = 0.6869, dev_loss = 1.216, dev_acc = 0.708\n",
      "\n",
      "After round 24, train_loss = 0.6785, dev_loss = 1.2207, dev_acc = 0.7081\n",
      "\n",
      "After round 25, train_loss = 0.6722, dev_loss = 1.2282, dev_acc = 0.7076\n",
      "\n",
      "After round 26, train_loss = 0.6647, dev_loss = 1.231, dev_acc = 0.7059\n",
      "\n",
      "After round 27, train_loss = 0.6567, dev_loss = 1.2331, dev_acc = 0.7075\n",
      "\n",
      "After round 28, train_loss = 0.6503, dev_loss = 1.2374, dev_acc = 0.7072\n",
      "\n",
      "After round 29, train_loss = 0.6434, dev_loss = 1.2418, dev_acc = 0.7076\n",
      "\n",
      "After round 30, train_loss = 0.6367, dev_loss = 1.2456, dev_acc = 0.7061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_net = to_device(FederatedNet(), device)\n",
    "history_FL = []\n",
    "traffic=[]\n",
    "weights=[]\n",
    "load_model=None\n",
    "total_length_dataset=len(train_dataset)\n",
    "for i in range(rounds):\n",
    "    curr_parameters = global_net.state_dict()\n",
    "    new_model=None\n",
    "    for client in clients:\n",
    "        client_parameters = client.train(curr_parameters)\n",
    "        fraction = client.get_dataset_size()/total_length_dataset\n",
    "        new_model=average_models(new_model,client_parameters,fraction)\n",
    "    load_model=new_model.copy()\n",
    "    params = list(load_model)\n",
    "    total_norm = 0.0\n",
    "    for key, value in load_model.items():\n",
    "        total_norm += torch.norm(value.view(-1)).item()\n",
    "    weights.append(total_norm)\n",
    "    global_net.load_state_dict(new_model)\n",
    "    train_loss, train_acc = global_net.evaluate(train_dataset)\n",
    "    dev_loss, dev_acc = global_net.evaluate(test_dataset)\n",
    "    print('After round {}, train_loss = {}, dev_loss = {}, dev_acc = {}\\n'.format(i + 1, round(train_loss, 4), \n",
    "            round(dev_loss, 4), round(dev_acc, 4)))\n",
    "    traffic.append(2*num_clients)\n",
    "    history_FL.append((train_acc, dev_acc,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdMAAAHUCAYAAABh+8IVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABmTklEQVR4nO3deVxUVeMG8GfYkV1QNhGXXHAJFZDFXMpEMdcW0fyhpr5Fuab5vi65ZqG2aaaW5ZKWYkUq5Yq7hpWSpOWSuaEIESgMKoIM5/fHiZGRfZsLw/P9fO5nZu7c5dy5xeM599xzVUIIASIiIqowI6ULQEREVNsxTImIiCqJYUpERFRJDFMiIqJKYpgSERFVEsOUiIiokhimRERElcQwJSIiqiSGKRERUSUxTMkgrV+/HiqVSjuZmJjA1dUVQ4cOxcWLF5UuXqnmzZsHlUqldDHKJTU1Febm5lCpVDh58qTSxSHSK4YpGbR169bh+PHj2LdvH8aPH4/o6Gg88cQTuH37ttJFMzgbN25ETk4OAGDNmjUKl4ZIvximZNDatWuHgIAA9OjRA7NmzcL06dORkpKCbdu2KV00g7N27Vo0bNgQfn5+2Lx5M7KyspQuUpEePHiA3NxcpYtBBoZhSnWKr68vAODvv//WmR8dHY3AwEDUq1cPNjY26NWrF44fP66zzKhRo9CkSZNC2yyqSValUmH8+PHYuHEjvLy8UK9ePXh7e+OHH34otP6OHTvQoUMHmJubo2nTpnjvvfeKLPs333wDf39/2NnZoV69emjWrBlGjx5d4vF27NgRXbt2LTRfo9HA3d0dzz77rHbeqlWr4O3tDWtra9jY2KB169aYOXNmidvP9/PPP+P3339HWFgY/vOf/yAjIwNRUVGFlsvLy8Py5cvRoUMHWFpawt7eHgEBAYiOjtZZbtOmTQgMDIS1tTWsra3RoUMHndpukyZNMGrUqELb79GjB3r06KH9fOjQIahUKmzcuBFTp06Fu7s7zM3N8ddff+Gff/7Ba6+9hjZt2sDa2hoNGzbEU089haNHjxbabnZ2NhYsWAAvLy9YWFjA0dERTz75JGJjYwEAPXv2ROvWrfHoc0OEEHjsscfwzDPPlOl3pNqLYUp1ypUrVwAALVu21M7btGkTBg4cCFtbW2zevBlr1qzB7du30aNHDxw7dqzC+9qxYwc+/vhjLFiwAFFRUahfvz4GDx6My5cva5fZv38/Bg4cCBsbG0RGRuLdd9/F119/jXXr1uls6/jx4wgNDUWzZs0QGRmJHTt2YM6cOaXWsF566SUcO3as0HXivXv34ubNm3jppZcAAJGRkXjttdfQvXt3bN26Fdu2bcPrr7+Ou3fvlulY84Nu9OjRGDp0KOrVq1dkU++oUaMwadIk+Pn5YcuWLYiMjMSAAQNw9epV7TJz5szB8OHD4ebmhvXr12Pr1q0YOXIkrl27VqayFGXGjBlISEjAJ598gu+//x4NGzbErVu3AABz587Fjh07sG7dOjRr1gw9evTAoUOHtOvm5uYiJCQEb731Fvr164etW7di/fr1CAoKQkJCAgBg0qRJuHDhAvbv36+z3127duHSpUsYN25chctOtYQgMkDr1q0TAMRPP/0kHjx4IDIzM8Xu3buFi4uL6Natm3jw4IEQQgiNRiPc3NxE+/bthUaj0a6fmZkpGjZsKIKCgrTzRo4cKTw9PQvta+7cueLR/5UACGdnZ6FWq7XzkpOThZGRkYiIiNDO8/f3F25ubiIrK0s7T61Wi/r16+ts87333hMARHp6erl+h9TUVGFmZiZmzpypM3/IkCHC2dlZ+zuMHz9e2Nvbl2vb+e7evStsbW1FQECAdt7IkSOFSqUSf/31l3bekSNHBAAxa9asYrd1+fJlYWxsLIYPH17iPj09PcXIkSMLze/evbvo3r279vPBgwcFANGtW7dSjyM3N1c8ePBA9OzZUwwePFg7f8OGDQKA+Oyzz4pdV6PRiGbNmomBAwfqzA8JCRHNmzcXeXl5pe6fajfWTMmgBQQEwNTUFDY2NujTpw8cHBywfft2mJiYAAAuXLiAmzdvIiwsDEZGD/93sLa2xnPPPYeffvoJ9+7dq9C+n3zySdjY2Gg/Ozs7o2HDhtoa1t27d3HixAk8++yzsLCw0C5nY2OD/v3762zLz88PADBkyBB8/fXXSExMLFMZHB0d0b9/f3zxxRfIy8sDANy+fRvbt2/HiBEjtL9D586dkZ6ejmHDhmH79u1ITU0t83F+/fXXUKvVOk3Oo0ePhhBCp4a9a9cuACixlhYTEwONRlPlNbnnnnuuyPmffPIJOnXqBAsLC5iYmMDU1BT79+/HuXPndMptYWFRYpO6kZERxo8fjx9++EFbW7106RJ2796N1157rdb1zKbyY5iSQduwYQNOnDiBAwcO4JVXXsG5c+cwbNgw7fdpaWkAAFdX10Lrurm5IS8vr8I9fx0dHQvNMzc313bMuX37NvLy8uDi4lJouUfndevWDdu2bUNubi5GjBiBRo0aoV27dti8eXOp5Rg9ejQSExMRExMDANi8eTOys7N1rjmGhYVh7dq1uHbtGp577jk0bNgQ/v7+2nVKsmbNGlhYWKBPnz5IT09Heno6Hn/8cTRp0gTr16+HRqMBAPzzzz8wNjYu8njz/fPPPwCARo0albrf8ijq/H7wwQd49dVX4e/vj6ioKPz00084ceIE+vTpo9N56p9//oGbm5vOP7aKMnr0aFhaWuKTTz4BAKxYsQKWlpalXtcmw8AwJYPm5eUFX19fPPnkk/jkk08wduxY7N69G99++y2Ah4GXlJRUaN2bN2/CyMgIDg4OAAALCwtkZ2cXWq48tbiCHBwcoFKpkJycXOi7ouYNHDgQ+/fvR0ZGBg4dOoRGjRrhxRdfLNRR6lG9e/eGm5ubtpa4bt06+Pv7o02bNjrLvfTSS4iNjUVGRgZ27NgBIQT69etX4rXKP//8E8eOHcP9+/fRuHFjODg4aKerV68iMTERe/bsAQA0aNAAGo2myGPL16BBAwDAjRs3Sjym8p6LomqGX375JXr06IFVq1bhmWeegb+/P3x9fZGZmVmoTDdv3tTW7ItjZ2eHkSNH4vPPP8etW7ewbt06vPjii7C3ty9xPTIMDFOqU5YsWQIHBwfMmTMHeXl5aNWqFdzd3bFp0yadnph3795FVFSUtocvIHuQpqSk6PQEzsnJ0YZFeVlZWaFz58747rvvcP/+fe38zMxMfP/998WuZ25uju7du2Px4sUAgFOnTpW4H2NjY4SFhWHbtm04evQoTp48WWJtycrKCiEhIZg1axZycnLwxx9/FLtsfiejzz77DAcPHtSZdu7cCVNTU6xduxYAEBISAkD2Gi5OcHAwjI2NS1wGkOfi9OnTOvP+/PNPXLhwocT1ClKpVDA3N9eZd/r06UL/OAkJCcH9+/exfv36Urc5ceJEpKam4vnnn0d6ejrGjx9f5vJQLafwNVuiapHfAenEiROFvluyZIkAIDZu3CiEEOKrr74SAETfvn3F9u3bxddffy38/PyEmZmZOHr0qHa9y5cvC1NTU9GjRw+xY8cOERUVJbp37y6aNm1aZAekcePGFdr3ox1n9u7dK4yMjMQTTzwhtm7dKr799lvh5+cnPDw8dLY5e/Zs8dJLL4kvv/xSHDp0SGzbtk08+eSTwtTUVPz++++l/h4XLlwQAESjRo2EpaVloY5MY8eOFRMmTBCRkZHi8OHDYsuWLaJDhw7Czs5OpKSkFLnNBw8eCBcXF+Hl5VXsfp999llhamqq3UZYWJhQqVTi5ZdfFtHR0WLPnj1i0aJF4qOPPtI5VgDi+eefF1FRUWLfvn3io48+EnPmzNEu8+WXXwoA4tVXXxX79u0Ta9asEa1atRKurq5FdkD65ptvCpVtzpw5QqVSiTlz5oj9+/eLlStXChcXF9G8eXOdjmYPHjzQ/tb//e9/xa5du8SOHTvEnDlzxObNmwttNyQkRAAQTzzxRLG/CxkehikZpJLCNCsrSzRu3Fi0aNFC5ObmCiGE2LZtm/D39xcWFhbCyspK9OzZU/z444+F1t25c6fo0KGDsLS0FM2aNRMff/xxsb15yxKmQggRHR0tHn/8cWFmZiYaN24sFi1aVGibP/zwgwgJCRHu7u7CzMxMNGzYUPTt21cn7EsTFBQkABTZU/aLL74QTz75pHB2dhZmZmbCzc1NDBkyRJw+fbrY7W3btk0AEEuXLi12md27dwsA4v333xdCyF6vH374oWjXrp0wMzMTdnZ2IjAwUHz//fc6623YsEH4+fkJCwsLYW1tLTp27CjWrVun/T4vL08sWbJENGvWTFhYWAhfX19x4MCBYnvzFhWm2dnZ4o033hDu7u7CwsJCdOrUSWzbtq3IXttZWVlizpw5okWLFsLMzEw4OjqKp556SsTGxhba7vr16wUAERkZWezvQoZHJcQjdxkTEVGF5fcCv3r1KkxNTZUuDumJidIFICKq7bKzs/Hrr7/il19+wdatW/HBBx8wSOsY1kyJiCrp6tWraNq0KWxtbfHiiy/i448/hrGxsdLFIj1imBIREVUSb40hIiKqJIYpERFRJTFMiYiIKom9eYuQl5eHmzdvwsbGhgNUExHVYUIIZGZmljo+M8O0CDdv3oSHh4fSxSAiohri+vXrJT6AgWFahPzHZl2/fh22trYKl4aIiJSiVqvh4eGh8zjFojBMi5DftGtra8swJSKiUi/5sQMSERFRJTFMiYiIKolhSkREVEm8ZlpBQgjk5uZCo9EoXRQqJ2NjY5iYmPC2JyKqMgzTCsjJyUFSUhLu3bundFGogurVqwdXV1eYmZkpXRQiMgAM03LKy8vDlStXYGxsDDc3N5iZmbGGU4sIIZCTk4N//vkHV65cQYsWLUq8EZuIqCwYpuWUk5ODvLw8eHh4oF69ekoXhyrA0tISpqamuHbtGnJycmBhYaF0kYioluM/ySuItZnajeePiKoS/6IQERFVEsOUiIiokhimVGFNmjTB0qVLFd8GEZHS2AGpDunRowc6dOhQZeF14sQJWFlZVcm2iIhqM4Yp6RBCQKPRwMSk9P80GjRooIcSERHVfGzmrQpCAHfvKjMJUaYijho1CocPH8ayZcugUqmgUqlw9epVHDp0CCqVCnv27IGvry/Mzc1x9OhRXLp0CQMHDoSzszOsra3h5+eHffv26Wzz0SZalUqFzz//HIMHD0a9evXQokULREdHl+unTEhIwMCBA2FtbQ1bW1sMGTIEf//9t/b73377DU8++SRsbGxga2sLHx8fnDx5EgBw7do19O/fHw4ODrCyskLbtm2xc+fOcu2fiGoBIYDMTOCvv4AffwS++w5YtQqYNw949VXg2WeBLl2Axx4DLl3SS5FYM60K9+4B1tbK7PvOHaAMTa3Lli3Dn3/+iXbt2mHBggUAZM3y6tWrAID//ve/eO+999CsWTPY29vjxo0b6Nu3LxYuXAgLCwt88cUX6N+/Py5cuIDGjRsXu5/58+djyZIlePfdd7F8+XIMHz4c165dQ/369UstoxACgwYNgpWVFQ4fPozc3Fy89tprCA0NxaFDhwAAw4cPR8eOHbFq1SoYGxsjPj4epqamAIBx48YhJycHR44cgZWVFc6ePQtrpc4LEVWOWg1cuPBwOn8euH4d+PtvOWVllW07SUlA8+bVW1YwTOsMOzs7mJmZoV69enBxcSn0/YIFC9CrVy/tZ0dHR3h7e2s/L1y4EFu3bkV0dDTGjx9f7H5GjRqFYcOGAQDeeecdLF++HL/88gv69OlTahn37duH06dP48qVK/Dw8AAAbNy4EW3btsWJEyfg5+eHhIQETJs2Da1btwYAtGjRQrt+QkICnnvuObRv3x4A0KxZs1L3SUQK0miAq1d1AzP/fXJy6etbWQHOzg+nhg11Pzs7A48/Xu2HATBMq0a9erKGqNS+q4Cvr6/O57t372L+/Pn44YcfcPPmTeTm5iIrKwsJCQklbufxAv/hWllZwcbGBikpKWUqw7lz5+Dh4aENUgBo06YN7O3tce7cOfj5+WHKlCkYO3YsNm7ciKeffhovvPACmv/7r86JEyfi1Vdfxd69e/H000/jueee0ykPEelZRoasTd64ofuaP125AuTkFL++qyvQqtXDqWlT3aCsQR0gGaZVQaWqUSe1Ih7tlTtt2jTs2bMH7733Hh577DFYWlri+eefR05J/+ED2ibXfCqVCnl5eWUqgxCiyHGOC86fN28eXnzxRezYsQO7du3C3LlzERkZicGDB2Ps2LHo3bs3duzYgb179yIiIgLvv/8+JkyYUKb9E1E5CQHcvAn8+ivw228yHAsGZ2Zm6duwsABattQNzfzJ1rb6j6GKMEzrEDMzszI/Mu7o0aMYNWoUBg8eDAC4c+eO9vpqdWnTpg0SEhJw/fp1be307NmzyMjIgJeXl3a5li1bomXLlnj99dcxbNgwrFu3TltODw8PhIeHIzw8HDNmzMBnn33GMCWqCkIAly/L4Dx1Sr7++ivwzz8lr1e/PuDhATRqpPvq4SFrmo0bAwYwvKfiYbpy5Uq8++67SEpKQtu2bbF06VJ07dq12OW/+uorLFmyBBcvXoSdnR369OmD9957D46OjtploqKiMHv2bFy6dAnNmzfH22+/rf1jW5c1adIEP//8M65evQpra+sSOwU99thj+O6779C/f3+oVCrMnj27zDXMinr66afx+OOPY/jw4Vi6dKm2A1L37t3h6+uLrKwsTJs2Dc8//zyaNm2KGzdu4MSJE3juuecAAJMnT0ZISAhatmyJ27dv48CBAzohTERlcP8+kJ4OpKQAp08/DM34eNls+yhjY6BNG6BjR6BFC93AdHev9a12ZaVomG7ZsgWTJ0/GypUr0aVLF3z66acICQnB2bNni+wxeuzYMYwYMQIffvgh+vfvj8TERISHh2Ps2LHYunUrAOD48eMIDQ3FW2+9hcGDB2Pr1q0YMmQIjh07Bn9/f30fYo3yxhtvYOTIkWjTpg2ysrJw5cqVYpf98MMPMXr0aAQFBcHJyQn/+9//oFarq7V8KpUK27Ztw4QJE9CtWzcYGRmhT58+WL58OQD5UO+0tDSMGDECf//9N5ycnPDss89i/vz5AACNRoNx48bhxo0bsLW1RZ8+ffDhhx9Wa5mJarS7d4Fr14CEBNnsevu2DMr09IfvH52XnV389szMZIeeTp3k1LEj0L49YGmpl8OpyVRClPFGxWrg7++PTp06YdWqVdp5Xl5eGDRoECIiIgot/95772HVqlW4VOC+oeXLl2PJkiW4fv06ACA0NBRqtRq7du3SLtOnTx84ODhg8+bNZSqXWq2GnZ0dMjIyYPtIm/39+/dx5coVNG3alI/uqsV4HqnWEwJITZVBee3aw6ng57S0im1bpQIcHB7WOPPD08sLeKRfhKErKQ8KUqxmmpOTg7i4OEyfPl1nfnBwMGJjY4tcJygoCLNmzcLOnTsREhKClJQUfPvtt3jmmWe0yxw/fhyvv/66znq9e/cucQi97OxsZBf411h118CIiMpFo5G3i5w48XD6/Xd5j3tpbG0BT0/Z9OroKEPS3v7ha8H3+a82NgZxHVOfFAvT1NRUaDQaODs768x3dnZGcjH3FwUFBeGrr75CaGgo7t+/j9zcXAwYMEDbDAgAycnJ5domAERERGibComIFCWErFXmh+YvvwBxccXffufiIsPS01N25sl/n//Z3l6vxa+rFO+A9OitEMXdHgHInp0TJ07EnDlz0Lt3byQlJWHatGkIDw/HmjVrKrRNAJgxYwamTJmi/axWq3XudSQiqnJ5eXJggoQEOZ09K4PzxAnZfPuoevVkU6ufH9C5s2x+9fSUt5aQ4hQLUycnJxgbGxeqMaakpBSqWeaLiIhAly5dMG3aNABygAArKyt07doVCxcuhKurK1xcXMq1TQAwNzeHubl5JY+IiKiAzMyHQXn9+sP3+dONG8CDB0Wva2IiO/p07izD089PXq8swwMoSBmKnRkzMzP4+PggJiZG57aVmJgYDBw4sMh17t27V+hpJsbGxgBk7RMAAgMDERMTo3PddO/evQgKCqrqQyAikvLygDNngGPHgKNH5WtiYunrGRvL20caN5bjx/r6yuD09maNs5ZR9J85U6ZMQVhYGHx9fREYGIjVq1cjISEB4eHhAGTza2JiIjZs2AAA6N+/P/7zn/9g1apV2mbeyZMno3PnznBzcwMATJo0Cd26dcPixYsxcOBAbN++Hfv27cOxY8cUO04iMjDZ2cDJkzI4jx6VTy4p6h5Me3sZlMVNrq6sbRoIRc9iaGgo0tLSsGDBAiQlJaFdu3bYuXMnPD09AQBJSUk6Y8GOGjUKmZmZ+PjjjzF16lTY29vjqaeewuLFi7XLBAUFITIyEm+++SZmz56N5s2bY8uWLXX+HlMiqgS1GoiNfVjr/PnnwvdjWlsDQUFA167AE0/I65u1aDg8qhxF7zOtqXifqeHjeaRiCSHHmI2NldOPP8om3Ef/VDZoIIMzf/L2Zi3TANX4+0yJiGqE7Gw51uyPPz4M0KJupWvWTDc8W7SQgxsQgWFa5/Xo0QMdOnQocVCL2rAPolLljxiU/+ivX36RAXryZOEmW1NTwMdHNtt26QIEBsrrm0TFYJgSkWHIf3Zm/q0oj043bshB3Ivi5CRDMyhITr6+7E1L5cIwJaLa5++/ZSegn36Sr3FxRfemLYqLi3yiSYcOD2uejz3GJluqFA6+WAWEkA9nUGIqT/exu3fvYsSIEbC2toarqyvef//9Qsvk5OTgv//9L9zd3WFlZQV/f38cOnQIAJCRkQFLS0vs3r1bZ53vvvsOVlZWuFPccGePuH37NkaMGAEHBwfUq1cPISEhuHjxovb7a9euoX///nBwcICVlRXatm2LnTt3atcdPnw4GjRoAEtLS7Ro0QLr1q0r+49Atc/9+/I65ocfAkOHAk2ayEAcOBCIiAAOHHgYpA4OcrCDfv2AV18F3nkH2LgROHRIPoszOxtISpJNvKtXA6NG8donVQnWTKvAvXuyV7wS7twp++MCp02bhoMHD2Lr1q1wcXHBzJkzERcXhw4dOmiXeemll3D16lVERkbCzc0NW7duRZ8+fXDmzBm0aNECzzzzDL766iv06dNHu86mTZswcOBAWJfxRxg1ahQuXryI6Oho2Nra4n//+x/69u2Ls2fPwtTUFOPGjUNOTg6OHDkCKysrnD17Vrvt2bNn4+zZs9i1axecnJzw119/ISsrq8y/F9UCycnAvn0Pa52//VZ4pCCVSj7RJCAA8PeXIwU99lideXYm1UCCCsnIyBAAREZGRqHvsrKyxNmzZ0VWVpZ23p07Qsg6ov6nO3fKdkyZmZnCzMxMREZGauelpaUJS0tLMWnSJCGEEH/99ZdQqVQiMTFRZ92ePXuKGTNmCCGE+O6774S1tbW4e/eu9reysLAQO3bsKHbf3bt31+7jzz//FADEjz/+qP0+NTVVWFpaiq+//loIIUT79u3FvHnzitxW//79xUsvvVS2gy5BUeeRFHT+vBCLFgkRGCiESlX4P3RnZyEGDBDi7beF2L9fiCL+3ySqDiXlQUGsmVaBevWKf6CDPvZdFpcuXUJOTg4CAwO18+rXr49WrVppP//6668QQqBly5Y662ZnZ8PR0REA8Mwzz8DExATR0dEYOnQooqKiYGNjg+Dg4DKV49y5czAxMdEZRMPR0RGtWrXCuXPnAAATJ07Eq6++ir179+Lpp5/Gc889h8cffxwA8Oqrr+K5557Dr7/+iuDgYAwaNIhDRdZGeXmy1rl9O7Btm3y8WEG+vvL2E39/OXl6simWajSGaRVQqWp+65Iow8XVvLw8GBsbIy4uTjvmcb78ZlYzMzM8//zz2LRpE4YOHYpNmzYhNDS00JjJ5S2HKPBkn7Fjx6J3797YsWMH9u7di4iICLz//vuYMGECQkJCcO3aNezYsQP79u1Dz549MW7cOLz33ntl2j8p6P59YP9+GaDR0bITUT5TU+Cpp4BBg4D+/eV4tUS1iR5qybVOeZt5a4PMzExhamoqtmzZop1369YtUa9ePW0T7IULFwQAceTIkRK3dfDgQWFqaip+//13YWxsLI4fP17i8mVt5v3mm2+KXH/69Omiffv2RX73ySefCBsbmxL3X5Taeh5rlQcPhPj1VyFWrRLiueeEsLLSbbq1tRVi2DAhIiPZbEs1Fpt5SYe1tTXGjBmDadOmwdHREc7Ozpg1axaMjB526G7ZsiWGDx+OESNG4P3330fHjh2RmpqKAwcOoH379ujbty8AoHv37nB2dsbw4cPRpEkTBAQElLkcLVq0wMCBA/Gf//wHn376KWxsbDB9+nS4u7trnxY0efJkhISEoGXLlrh9+zYOHDgALy8vAMCcOXPg4+ODtm3bIjs7Gz/88IP2O1KQEPJezp9/fjjFxQGPdg5zd5e9cAcNArp3B8zMFCkuUVVjmNYh7777Lu7cuYMBAwbAxsYGU6dORcYj9+atW7cOCxcuxNSpU5GYmAhHR0cEBgZqgxSQD18fNmwY3n33XcyZM6fc5Vi3bh0mTZqEfv36IScnB926dcPOnTthamoKANBoNBg3bhxu3LgBW1tb9OnTBx9++CEA2cw8Y8YMXL16FZaWlujatSsiIyMr8atQhWRmypGDCoZnUlLh5ezsZE/boCB5u4qPD699kkHiQPdF4ED3ho/nsZxyc+WtKrt3y+nUKdmJqCBjY3mPZ36noYAAoGVLwIi3s1PtxYHuiahybtwA9uyR4RkTU3iEIQ+Ph/d5+vvLR46VtXs5kYFhmBKRlJMjn9WZX/s8c0b3+/r1geBgICQEePppwM1NmXIS1UAMU6K66v59ObrQzz/LW1b275djVOZTqeT1zj59ZID6+sqmXCIqhGFKVBdoNMC5c3JM2hMn5Ovp0/JaaEENG8rw7NNH1kL/HayDiErGMK0g9tuq3Qz6/AkBXL2qG5y//qpb68zn5CRrn126yADt0IEdhogqgGFaTvm3b9y7dw+WlpYKl4Yq6t69ewAens9aLy8POH4ciIwEoqKKvk3Fyko21fr5yQD18+MwfURVhGFaTsbGxrC3t0dKSgoAoF69etph8KjmE0Lg3r17SElJgb29faFhE2sVIWSNMzIS2LJFDpqQz9QU8PbWDc7WrXnNk6iaMEwrwMXFBQC0gUq1j729vfY81jp//CEDNDIS+Ouvh/NtbIDBg4HQUDnOLe+fJdIbhmkFqFQquLq6omHDhnjw6HMWqcYzNTWtfTXSixdl7TMyUoZpPktLOTD80KGyxy0DlEgRDNNKMDY2rn1/lKl2EELe5xkdDWzdKptz85mZyeAcOlQO0afUk+mJSIthSlRTPHgAHD0qA3T7dtkjN5+xsRwoYehQOUi8vb1ChSSiojBMiZSkVsvRhrZvB3buBNLTH35nYQH06gUMGCCftNKggWLFJKKSMUyJ9O36deD772WAHjwoa6T5GjSQTbcDB8og5Vi3RLUCw5RIX+LigLfekiFaUKtWMjwHDJADx/M6PFGtwzAlqm4//SRDdOdO+Vmlks/3zA/QVq2ULR8RVRrDlKi6/PgjsGABsHev/GxkBAwfDsycKQdQICKDwTAlqmqHD8sQPXBAfjY2BkaMkCH62GPKlo2IqgXDlKgqCCEfYbZggby9BZBD+o0aBUyfDjRrpmjxiKh6MUyJKkMIYM8eGaLHj8t5ZmbA2LHA//4HNG6sbPmISC8YpkQVcfs2sHEjsHr1w+H9LCyAl18G/vtfwN1d2fIRkV4xTInKSgggNlYG6NdfA/fvy/n16gHh4cAbbwCursqWkYgUwTAlKk1RtVAAaN8eeOUV4P/+D7CzU658RKQ4hilRUYSQ10A//VS3FmppKcfHffllwN+fD9YmIgAMUyJd6ekPa6G///5wfn4tdPhwDjJPRIUYKV2AlStXomnTprCwsICPjw+O5t9WUIRRo0ZBpVIVmtq2batdZv369UUucz+/ZkFUlEuXgIkTgUaN5Ovvv8ta6KhRsob622/AuHEMUiIqkqI10y1btmDy5MlYuXIlunTpgk8//RQhISE4e/YsGhdxS8GyZcuwaNEi7efc3Fx4e3vjhRde0FnO1tYWFy5c0JlnwYcm06OEAI4cAT78UD72TAg5v21b2aHo//6P4UlEZaJomH7wwQcYM2YMxo4dCwBYunQp9uzZg1WrViEiIqLQ8nZ2drAr0NFj27ZtuH37Nl566SWd5VQqFVxcXMpcjuzsbGRnZ2s/q9Xq8h4K1SY5OfI66AcfAKdOPZwfEgJMmQL07MlroURULoo18+bk5CAuLg7BwcE684ODgxEbG1umbaxZswZPP/00PD09debfuXMHnp6eaNSoEfr164dTBf9gFiEiIkIb1HZ2dvDw8CjfwVDtkJYGvPMO0KQJEBYmg9TSUl4LPXtWDkT/9NMMUiIqN8XCNDU1FRqNBs7OzjrznZ2dkZycXOr6SUlJ2LVrl7ZWm69169ZYv349oqOjsXnzZlhYWKBLly64ePFisduaMWMGMjIytNP169crdlBUM50/L5ttPTyAWbOApCR5P+jbb8tni37yCeDlpXQpiagWU7w3r+qRWoAQotC8oqxfvx729vYYNGiQzvyAgAAEBARoP3fp0gWdOnXC8uXL8dFHHxW5LXNzc5ibm5e/8FSz/fGHDM+Czw/t2FE25Q4ZIof9IyKqAoqFqZOTE4yNjQvVQlNSUgrVVh8lhMDatWsRFhYGs1L+IBoZGcHPz6/EmikZmOvXgblzgS++APLyZLPtgAHA668D3bqxGZeIqpxizbxmZmbw8fFBTEyMzvyYmBgEBQWVuO7hw4fx119/YcyYMaXuRwiB+Ph4uHKYN8N3+7YcXL5lS2DdOhmkzz8PnDsHbNsGdO/OICWiaqFoM++UKVMQFhYGX19fBAYGYvXq1UhISEB4eDgAeS0zMTERGzZs0FlvzZo18Pf3R7t27Qptc/78+QgICECLFi2gVqvx0UcfIT4+HitWrNDLMZECsrKAjz+WnYvS0+W8bt2AJUvkKEVERNVM0TANDQ1FWloaFixYgKSkJLRr1w47d+7U9s5NSkpCQkKCzjoZGRmIiorCsmXLitxmeno6Xn75ZSQnJ8POzg4dO3bEkSNH0Llz52o/HtIzjQbYsAGYMwe4cUPOa9cOWLxY3ubCWigR6YlKiPw71SmfWq2GnZ0dMjIyYGtrq3Rx6FFCAD/8AMyY8XDgeQ8P4K235EALxsbKlo+IDEZZ80Dx3rxE5fLTT/J5ofnDTjo4yB6748bJ54kSESmAYUq1w82bsnPRl1/KzxYWwKRJwPTpHPKPiBTHMKWaLTsbWLZMNuHeuSOvg44aBSxYIAelJyKqARimVHPt2iVrn/n3CPv7A8uXA35+ypaLiOgRij+CjaiQv/4C+vcH+vaVQersDKxfD8TGMkiJqEZimFLNcecOMHOmfATaDz8AJibA1KnAn38CI0cCRvzPlYhqJjbzkvKEACIjgWnTgMREOS84WF4rbd1a2bIREZUBw5SU9dtvwIQJD291adpUPqx7wAAOukBEtQbbzUgZQgAffQT4+MggtbSUPXb/+AMYOJBBSkS1CmumpH/Z2cCrr8rB6AFg8GBg6VKgcWNFi0VEVFEMU9KvpCTg2WflSEZGRsC778pHo7EmSkS1GMOU9OfECVkLTUyUoxZFRgK9eytdKiKiSuM1U9KPL78EunaVQerlBfzyC4OUiAwGw5Sql0Yjb3kJC5PXSvv3l028LVooXTIioirDMKXqc/s28MwzwHvvyc8zZwLbtgF8rB0RGRheM6Xqce6cvMXl4kV528u6dUBoqNKlIiKqFgxTqno//AC8+CKQmSlvd9m+HejQQelSERFVGzbzUtURAoiIkKMXZWbKDkcnTjBIicjgMUypauTlAePHy+uiQgCvvALs2wc0bKh0yYiIqh2beany8vJkeH7+uRx8YflyYNw4pUtFRKQ3DFOqHI0GGDMG+OILOaLR+vXyNhgiojqEYUoVl5srnzO6aRNgbAxs3AgMG6Z0qYiI9I5hShXz4AEwfDjwzTfyId6bNwPPP690qYiIFMEwpfLLyZH3jG7bBpiaykAdOFDpUhERKYZhSuVz/76sge7YAZibA999B/Ttq3SpiIgUxTClssvKkk992bMHsLCQgzEEBytdKiIixTFMqWzu3pWDMRw4ANSrB3z/PfDUU0qXioioRmCYUukyM4F+/YAjRwBra2DnTjm6ERERAWCYUmnUaiAkBIiNlU972bULCApSulRERDUKw5SKl54uH+D9yy+Avb28Vtq5s9KlIiKqcRimVLS8PPnkl19+AerXB2JigE6dlC4VEVGNxDClor3/vmzStbCQA9Z37Kh0iYhqhLw82WiTkiKnf/4p+n1Wlhxhs6yTSiW3XdZJpZKPCq5Xr/BU1HwbG8DTE2jaVF6xqSpCAKmpQEKCLJeZWfGTqamcVCrd9R88kHfdlTZZWsqnOnp4yGOqSRimVNhPP8mnvwDAsmUMUqpzbt+Wz7c/e1a+njsHJCbKkExNlSNp1maOjjJUmzV7+Jr/vnFjGXj5hAD+/hu4ehW4dk2+Fnx/7Rpw71759m9qKsNVowGys+U+KnIM+cHauHHh966ucpRTfVEJUZHDMGxqtRp2dnbIyMiAbVX+E642uH1bhue1a3KUo82bdf8ZSVTDCCHv3FKp5B9oE5Oy/SebHxIFQzP/NTm59PXt7OQTBhs0kK+Pvq9XT+6jPLVNY+Oy12Tz8mTt9969h69FTfnfpafL8EtNLfm4jIxkKDVqJGva167JwCuNi4v8/XNyCk/lYW4uG8QenczN5Xm+dg24c6f07RgbA+7uQGQkEBhYvjIUVNY8YM2UHhJCPgHm2jWgeXNg9WoGKdUI2dkyCK5cAS5fllP++ytXgIwM3eULNisW1dxoZCS3d/t28fts1Aho0wbw8pJTkyYPA7NBA/nHvTbKzNT97Qr+nleuyObUa9fklE+lkr+Hp6f8HfJf8983blz87yGErMnn5Mjm3PyAzc6WgVcwMPPPTUmEkOf7+nXZtJw/FfycmCj3mZBQtU3aJWGY0kMrVgBbt8q/QFu26O+/QjI4N28CP/4op2PH5B9pC4uir+8VdY1PpZJ/zPP/0N+8Wb6mwLLWiFQq2byZH5r5r61bG+5//jY2wOOPy+lReXmyVn7lCnDjhvzHg6enDFIzs4rtT6V6eK20KqhU8uYCe3ugffuil9Fo5HEkJACPPVY1+y2N4mG6cuVKvPvuu0hKSkLbtm2xdOlSdC1mQIBRo0bhiy++KDS/TZs2+OOPP7Sfo6KiMHv2bFy6dAnNmzfH22+/jcGDB1fbMRiEX38Fpk6V7997D/DxUbY8VGvk5cnm0WPHHgbolStVvx8rK91re49e5zMyKrqJsajpwQMZEC1byiAnycgIcHOTU22W38Tr7q6/fSoaplu2bMHkyZOxcuVKdOnSBZ9++ilCQkJw9uxZNG7cuNDyy5Ytw6JFi7Sfc3Nz4e3tjRdeeEE77/jx4wgNDcVbb72FwYMHY+vWrRgyZAiOHTsGf39/vRxXraNWy+ujOTny6S8TJihdIqqhNBrg1i0Znvm1zuPH5fW4goyMZM3niSeALl2Adu1kgJV0Ta/glJsrA7JgcDo5lX7Voab18KS6Q9EOSP7+/ujUqRNWrVqlnefl5YVBgwYhIiKi1PW3bduGZ599FleuXIGnpycAIDQ0FGq1Grt27dIu16dPHzg4OGDz5s1lKled6oAkhLyfNDJS/vU6dUreV0q1Wl6eDKSyTpmZsmNK/pSWpvs5f97t20U3t1pZAQEBMjifeALw9zfcZlKqW2p8B6ScnBzExcVh+vTpOvODg4MRGxtbpm2sWbMGTz/9tDZIAVkzff3113WW6927N5YuXVrsdrKzs5FdoLuaWq0u0/4Nwpo1MkiNjWXPXQZprZGbC1y6VLgn6vnz5b9Vobzc3eWokvk1T29v2YuWqK5S7D//1NRUaDQaODs768x3dnZGchn6pSclJWHXrl3YtGmTzvzk5ORybzMiIgLz588vR+kNxO+/P2zSffttjrlbQ92/D/z5Z+HQ/PNP2XRaHiYmhSdjY1mzbNBANqU6Ocl7+PLfPzqvfn0GJ9GjFP9fQvXIRRAhRKF5RVm/fj3s7e0xaNCgSm9zxowZmDJlivazWq2Gh4dHqWWo1e7elddJ79+X4+9Om6Z0ieq03FzZe/XPP+V08eLD12vXiu/JWq/ew1s3Ct7G4eRUODTzR9khoqqnWJg6OTnB2Ni4UI0xJSWlUM3yUUIIrF27FmFhYTB7pL+2i4tLubdpbm4O89p601hFTZwoqziursCGDaXf3EVVIj1dXpa+cEE3MC9fLrmWaW8vw7JgYLZpI2+u56kjUp5iYWpmZgYfHx/ExMTo3LYSExODgQMHlrju4cOH8ddff2HMmDGFvgsMDERMTIzOddO9e/ciiE2YD335JbB2rfwrvGmTvJmMqlxuLnDmDPDzz3L66Sd5PbM4FhbynriWLYEWLeRr/vuGDVmrJKrJFG3mnTJlCsLCwuDr64vAwECsXr0aCQkJCA8PByCbXxMTE7Fhwwad9dasWQN/f3+0a9eu0DYnTZqEbt26YfHixRg4cCC2b9+Offv24dixY3o5phrvzz+Bf39fzJkD9OihaHFqktxc+fMkJ8tnoNvaPpysrEoPsxs3Hobmzz8DcXFFdwRq0kTWKguGZcuW8r5H1jKJaidFwzQ0NBRpaWlYsGABkpKS0K5dO+zcuVPbOzcpKQkJCQk662RkZCAqKgrLli0rcptBQUGIjIzEm2++idmzZ6N58+bYsmUL7zEF5PXRIUPk9dIePYA331S6RIoQAkhKkrXG06cfvp47V/yoOSqVDFUbG92QtbWVIXzihBzC7FG2tvIRsP7+8taRzp3ZEEBkiDjQfREM9j7TKVOADz+U3Tbj42v/MCdlkJVVODTPnJH3TBbF2lrebnv3rhzLQq2WAxWUhZGRHN4sIECGp7+/HJaOtU2i2qvG32dKenbpErB8uXy/bp3BBmluLnDyJLB/v5x+/LHo2qaRkWxaffxxGYD5r56euuEnhAzk/GAtOGVmytfcXPmgHR8f2RxMRHUPw7SumD1b/tXv3Rt45hmlS1NlhJCdkvfvl88wP3xYBlxBDRvKQQUKBqeXl+zwUxqV6uHg6y4u1XMMRFT7MUzrgl9/laMbAUAZhmms6RISZHDu3w8cOFD42ZMODsCTTwJPPw307Ck7+LAnLBFVJ4ZpXTBjhnx98UXZHlkLXbok7+LZvFl2FCrI0lIOa5cfnh06yFF9iIj0hWFq6PbvB/bulQ8TfOstpUtTLikp8rGqX30lbzXJZ2wse8X27CmnwMDa+6BmIjIMDFNDJgSQ/yCBV16Rz7Gq4e7cAbZtkwEaE/OwJ62Rkax5Dh8unxJnZ6doMYmIdDBMDdm338qurdbWsgNSDfXggaw8f/UVsH277kAHfn4yQEND2QGIiGouhqmhevAAmDVLvp86tUaOFJCYCCxZIq+FpqY+nP/YYzJAX3xR3r5CRFTTMUwN1Zo1cgT1Bg1kmNYg6ekyRJculfdwAjLrhw6VIernx963RFS7MEwN0d27QP7zWWfPlmPg1QDZ2cCKFfLRqbduyXldusgKdK9efEYmEdVe/PNliJYtkzdfNm0qOx4pTKORTbmzZ8tncwJy0IRFi4D+/VkLJaLaj2FqaNLSgMWL5fuFC4FHnveqT0IAe/YA//ufHBMXANzdgQULgBEjWBMlIsPBP2eG5p135Hh6HTrIi5AKOXFChujBg/KznZ0cO2LCBDk0HxGRIWGYGpJr14CPP5bvFy1S5HElf/0lr4F+/bX8bGYmA3TmTKB+fb0Xh4hILximhmTuXPmIlCefBIKDq203QsgHYV+4AJw///D1/Hk5H5DXQcPCZJPuv4+nJSIyWAxTQ/H778CGDfL9okVV0qsn/4ksv/+uG5p//ik7DBcnJEQW4fHHK10EIqJagWFqKGbOlOn3/PNy4NpKyskBxowBvvyy6O9NTIDmzeXDr1u10n1lcy4R1TUMU0Nw7Bjw/fdyBPi336705jIzZSbv3Ss36e9fODSbNZNj5xMREcO09hNCdpsFgLFjKz3+XkqKfHb4yZOy121UFNCnTxWUk4jIgDFMa7vvvwdiY+VDPefMqdSmLl8GeveWPXKdnIAdO6qkxZiIyOAxTGszjebhg78nTwbc3Cq8qfh4WQP9+2/Z+3bvXg4yT0RUVvq/EZGqzoYNsrtt/frAf/9b4c0cPAh06yaD9PHHZUWXQUpEVHYM09psyRL5OnMmYG9foU18842skWZmAt27A0eOVKqCS0RUJzFMa6tr1+RNn8bGwH/+U6FNrFghH7qdkwM89xywe7cc9o+IiMqHYVpb7dsnX/39AVvbcq0qBPDmm8D48fL9q68CW7YAFhbVUE4iojqAHZBqq5gY+dqrV7lWy80FwsPls8MBOdzfm2/yMWhERJXBMK2N8vKA/fvl+6efLvNq9+4Bw4YB0dFyDPxPPqlwCzERERXAMK2NTp8GUlMBa2vZzFtGI0fKILWwADZvBgYNqr4iEhHVJQzT2ii/ibdHjzKP6bd9O/Dtt3JM3d27Zc9dIiKqGuyAVBvldz4qYxNvZqbsbAQAU6cySImIqhrDtLa5fx84elS+L2OYzp0rnzPapEmlRxwkIqIiMExrm9hYICsLcHUF2rQpdfFffwWWLZPvV62Sg9cTEVHVYpjWNgWbeEu5n0WjAV5+WXb+HTqUT38hIqouDNPaphzXSz/+GIiLk6MaffhhNZeLiKgOY5jWJrduyQeNAqWG6fXrcjAGAFi8GHBxqeayERHVYQzT2uTgQTn+X5s2pY5GP3EicOcOEBjIgRmIiKpbucO0SZMmWLBgARISEqqkACtXrkTTpk1hYWEBHx8fHM3vqVqM7OxszJo1C56enjA3N0fz5s2xdu1a7ffr16+HSqUqNN2/f79Kyquo/PtLS6mVbtsmJxMT4NNP5WhHRERUfcr9Z3bq1KnYvn07mjVrhl69eiEyMhLZ2dkV2vmWLVswefJkzJo1C6dOnULXrl0REhJSYlAPGTIE+/fvx5o1a3DhwgVs3rwZrVu31lnG1tYWSUlJOpOFIYzinn+9tITxeDMzgQkT5Ps33gDat9dDuYiI6jpRQfHx8WLixImiQYMGwsHBQYwbN07ExcWVaxudO3cW4eHhOvNat24tpk+fXuTyu3btEnZ2diItLa3Yba5bt07Y2dmVqxyPysjIEABERkZGpbZTpS5fFgIQwsRECLW62MUmT5aLNW0qxN27eiwfEZEBKmseVLgB0NvbG8uWLUNiYiLmzp2Lzz//HH5+fvD29sbatWshhChx/ZycHMTFxSE4OFhnfnBwMGJjY4tcJzo6Gr6+vliyZAnc3d3RsmVLvPHGG8jKytJZ7s6dO/D09ESjRo3Qr18/nDp1qsSyZGdnQ61W60w1Tn6tNCAAsLEpcpG4OOCjj+R73lNKRKQ/FR6b98GDB9i6dSvWrVuHmJgYBAQEYMyYMbh58yZmzZqFffv2YdOmTcWun5qaCo1GA2dnZ535zs7OSE5OLnKdy5cv49ixY7CwsMDWrVuRmpqK1157Dbdu3dJeN23dujXWr1+P9u3bQ61WY9myZejSpQt+++03tGjRosjtRkREYP78+RX8JfSklFticnMf3lM6bBjQu7cey0ZEVNeVt8obFxcnxo8fLxwdHUXDhg3F1KlTxblz53SW+eWXX4SFhUWJ20lMTBQARGxsrM78hQsXilatWhW5Tq9evYSFhYVIT0/XzouKihIqlUrcu3evyHU0Go3w9vYWEyZMKLYs9+/fFxkZGdrp+vXrNauZV6MRwtFRtt8eO1bkIkuXyq/t7YVIStJz+YiIDFRZm3nLXTP18/NDr169sGrVKgwaNAimRTy1pE2bNhg6dGiJ23FycoKxsXGhWmhKSkqh2mo+V1dXuLu7w87OTjvPy8sLQgjcuHGjyJqnkZER/Pz8cPHixWLLYm5uDnNz8xLLq6j4eCAtTTbvdu5c6GveU0pEpKxyXzO9fPkydu/ejRdeeKHIIAUAKysrrFu3rsTtmJmZwcfHBzH5t3v8KyYmBkFBQUWu06VLF9y8eRN37tzRzvvzzz9hZGSERo0aFbmOEALx8fFwdXUtsTw1Wn4TbzGPXMu/pzQoCBg7Vr9FIyKiCoRpSkoKfv7550Lzf/75Z5zMH52njKZMmYLPP/8ca9euxblz5/D6668jISEB4eHhAIAZM2ZgxIgR2uVffPFFODo64qWXXsLZs2dx5MgRTJs2DaNHj4alpSUAYP78+dizZw8uX76M+Ph4jBkzBvHx8dpt1kol3F/Ke0qJiJRX7j+948aNw/Xr1wvNT0xMxLhx48q1rdDQUCxduhQLFixAhw4dcOTIEezcuROenp4AgKSkJJ17Tq2trRETE4P09HT4+vpi+PDh6N+/Pz7K78IKID09HS+//DK8vLwQHByMxMREHDlyBJ2LaB6tFbKyHj5y7ZH7SwveUzptGtCunZ7LRkREAACVEKXcw/IIa2trnD59Gs2aNdOZf+XKFTz++OPIzMys0gIqQa1Ww87ODhkZGbC1tVW2MPv3yxqpm5t8KGmBJ8VMmSIHsG/WDDhzhrfCEBFVtbLmQblrpubm5vj7778LzU9KSoKJSYXvtKHiFGziLRCk9+4Bq1fL9x9/zCAlIlJSucO0V69emDFjBjIyMrTz0tPTMXPmTPQqYZg7qqBihhDctQu4exfw9ORzSomIlFbuquT777+Pbt26wdPTEx07dgQAxMfHw9nZGRs3bqzyAtZpaWnAr7/K9z176nz1zTfy9YUXSn1GOBERVbNyh6m7uztOnz6Nr776Cr/99hssLS3x0ksvYdiwYcXeKkMVdOCAfORa27ZAgVt7srKAH36Q7194QaGyERGRVoUuclpZWeHll1+u6rLQo8rQxOvnp0C5iIhIR4V7DJ09exYJCQnIycnRmT9gwIBKF4r+Vcz9pV9/LV/ZxEtEVDOUO0wvX76MwYMH48yZM1CpVNqnw6j+/auu0WiqtoR11eXLwJUrcjSG7t21s9nES0RU85S7N++kSZPQtGlT/P3336hXrx7++OMPHDlyBL6+vjh06FA1FLGOym/iDQwErK21s9nES0RU85S7Znr8+HEcOHAADRo0gJGREYyMjPDEE08gIiICEydOLPXZoVRGxTTx5vfiff55NvESEdUU5a6ZajQaWP9bU3JycsLNmzcBAJ6enrhw4ULVlq6u0mhkT15Ap/NRVhbw/ffy/ZAhCpSLiIiKVO6aabt27bTDCfr7+2PJkiUwMzPD6tWrCw0xSBUUHw/cuiUfuVagLZdNvERENVO5w/TNN9/E3bt3AQALFy5Ev3790LVrVzg6OmLLli1VXsA6Kb+J98knZQekf7GJl4ioZip3mPbu3Vv7vlmzZjh79ixu3boFBwcHbY9eqqQi7i8t2MTLXrxERDVLua6Z5ubmwsTEBL///rvO/Pr16zNIq0pWFnDsmHxfoPPR7t2yibdxY6C2Pk2OiMhQlStMTUxM4OnpyXtJq9OxY0B2NuDuDrRqpZ3NsXiJiGqucvfmffPNNzFjxgzcunWrOspDBZt4/03NrCwgOlrOZhMvEVHNU+5rph999BH++usvuLm5wdPTE1ZWVjrf/5r/lBOqmCLuL2UTLxFRzVbuMB00aFA1FIMAAKmpQP6gFwUeucZevERENVu5w3Tu3LnVUQ4CHg7U0L494OICgAM1EBHVBuW+ZkrVqJgm3jt32MRLRFSTlbtmamRkVOJtMOzpWwlF3F/KJl4iopqv3GG6detWnc8PHjzAqVOn8MUXX2D+/PlVVrA6JysLuHpVvg8I0M7iQA1ERDVfucN04MCBheY9//zzaNu2LbZs2YIxY8ZUScHqnPxbjYyNAXt7AMCePQ+beP39lSsaERGVrMqumfr7+2NffjMllV9+mNavr23PZRMvEVHtUCVhmpWVheXLl6NRo0ZVsbm6KS1Nvjo6AuBADUREtUm5m3kfHdBeCIHMzEzUq1cPX375ZZUWrk4pWDPFwyZeDw828RIR1XTlDtMPP/xQJ0yNjIzQoEED+Pv7w8HBoUoLV6c8EqYci5eIqPYod5iOGjWqGopBBZt52cRLRFS7lPua6bp16/BNfrWpgG+++QZffPFFlRSqTipQM2UTLxFR7VLuMF20aBGcnJwKzW/YsCHeeeedKilUnVQgTNmLl4iodil3mF67dg1NmzYtNN/T0xMJCQlVUqg66d9m3vu2DTlQAxFRLVPuMG3YsCFOnz5daP5vv/0Gx39v66AK+Ldmuue6FzIz2cRLRFSblDtMhw4diokTJ+LgwYPQaDTQaDQ4cOAAJk2ahKFDh1ZHGeuGf8P0m18fAyCbeI34GAIiolqh3L15Fy5ciGvXrqFnz54wMZGr5+XlYcSIEbxmWhlpabgPc0T/3BAAm3iJiGoTlRBCVGTFixcvIj4+HpaWlmjfvj08PT2rumyKUavVsLOzQ0ZGBmxtbfWzU0tLbL8fjEHYjkaNgGvXWDMlIlJaWfOg3DXTfC1atECLFi0qujoVlJUF3L+PbyCroy+8wCAlIqpNyv0n+/nnn8eiRYsKzX/33XfxAtsmKyYtDXlQ4Xv0B8AmXiKi2qbcYXr48GE888wzheb36dMHR44cKXcBVq5ciaZNm8LCwgI+Pj44evRoictnZ2dj1qxZ8PT0hLm5OZo3b461a9fqLBMVFYU2bdrA3Nwcbdq0KfQM1hrn1i1kwA5q2AEAOnVSuDxERFQu5Q7TO3fuwMzMrNB8U1NTqNXqcm1ry5YtmDx5MmbNmoVTp06ha9euCAkJKfF+1SFDhmD//v1Ys2YNLly4gM2bN6N169ba748fP47Q0FCEhYXht99+Q1hYGIYMGYKff/65XGXTq1u3kAo5EIaNDWBurnB5iIioXMrdAcnPzw/9+/fHnDlzdObPmzcP33//PeLi4sq8LX9/f3Tq1AmrVq3SzvPy8sKgQYMQERFRaPndu3dj6NChuHz5Mur/OyD8o0JDQ6FWq7Fr1y7tvD59+sDBwQGbN28uU7n03gEpKgrHn38PQTiOpk2By5erf5dERFS6auuANHv2bDz33HO4dOkSnnrqKQDA/v37sWnTJnz77bdl3k5OTg7i4uIwffp0nfnBwcGIjY0tcp3o6Gj4+vpiyZIl2LhxI6ysrDBgwAC89dZbsLS0BCBrpq+//rrOer1798bSpUuLLUt2djays7O1n8tbw660AjXTIkZqJCKiGq7cYTpgwABs27YN77zzDr799ltYWlrC29sbBw4cKFctLjU1FRqNBs7OzjrznZ2dkZycXOQ6ly9fxrFjx2BhYYGtW7ciNTUVr732Gm7duqW9bpqcnFyubQJAREQE5s+fX+ayVzmGKRFRrVahGzCeeeYZ/Pjjj7h79y7++usvPPvss5g8eTJ8fHzKvS3VIyO5CyEKzcuXl5cHlUqFr776Cp07d0bfvn3xwQcfYP369cjKyqrQNgFgxowZyMjI0E7Xr18v93FUSloaw5SIqBar8N2MBw4cwP/93//Bzc0NH3/8Mfr27YuTJ0+WeX0nJycYGxsXqjGmpKQUqlnmc3V1hbu7O+zs7LTzvLy8IITAjRs3AAAuLi7l2iYAmJubw9bWVmfSK9ZMiYhqtXKF6Y0bN7Bw4UI0a9YMw4YNg4ODAx48eICoqCgsXLgQHTt2LPO2zMzM4OPjg5iYGJ35MTExCAoKKnKdLl264ObNm7hz54523p9//gkjIyM0atQIABAYGFhom3v37i12mzUCw5SIqFYrc5j27dsXbdq0wdmzZ7F8+XLcvHkTy5cvr9TOp0yZgs8//xxr167FuXPn8PrrryMhIQHh4eEAZPPriBEjtMu/+OKLcHR0xEsvvYSzZ8/iyJEjmDZtGkaPHq3tgDRp0iTs3bsXixcvxvnz57F48WLs27cPkydPrlRZqxWbeYmIarUyd0Dau3cvJk6ciFdffbXKhhEMDQ1FWloaFixYgKSkJLRr1w47d+7UjvOblJSkc8+ptbU1YmJiMGHCBPj6+sLR0RFDhgzBwoULtcsEBQUhMjISb775JmbPno3mzZtjy5Yt8K/JzzNjzZSIqFYr832mx48fx9q1a/H111+jdevWCAsLQ2hoKNzc3PDbb7+hTZs21V1WvdH7fabu7mh18wD+RCscPgx061b9uyQiotKVNQ/K3MwbGBiIzz77DElJSXjllVcQGRkJd3d35OXlISYmBpmZmVVS8DpHCDbzEhHVchV+BBsAXLhwAWvWrMHGjRuRnp6OXr16ITo6uirLpwi91kzv3UOulS3MkAMBI/z9N9CwYfXukoiIyqbKa6ZFadWqFZYsWYIbN26Ueag+esStW7gNB4h/T0UxoyQSEVENViVPzTQ2NsagQYMMolaqdwWaeB0cAJMKP2GWiIiUwkdQK409eYmIaj2GqdIYpkREtR7DVGnsyUtEVOsxTJXGmikRUa3HMFUaw5SIqNZjmCqNzbxERLUew1RprJkSEdV6DFOlMUyJiGo9hqnS2MxLRFTrMUyVxpopEVGtxzBVkhDIScuEGnYAGKZERLUVw1RJ9+4hLccaAGBkJGBvr2xxiIioYhimSirQxOvoCBjxbBAR1Ur8860kneulKoULQ0REFcUwVRJ78hIRGQSGqZLYk5eIyCAwTJXEMCUiMggMUyWxmZeIyCAwTJXEmikRkUFgmCqJYUpEZBAYpkpiMy8RkUFgmCqJNVMiIoPAMFUSw5SIyCAwTBV0L/Ue7sEKAMOUiKg2Y5gqRQik3ZJDCJqaCtjYKFweIiKqMIapUu7eReoDWwCAk6OAikPzEhHVWgxTpRS8XtqASUpEVJsxTJXCJ8YQERkMhqlSeI8pEZHBYJgqhbfFEBEZDIapUhimREQGg2GqFDbzEhEZDMXDdOXKlWjatCksLCzg4+ODo0ePFrvsoUOHoFKpCk3nz5/XLrN+/foil7l//74+DqfsWDMlIjIYJkrufMuWLZg8eTJWrlyJLl264NNPP0VISAjOnj2Lxo0bF7vehQsXYGtrq/3coEEDne9tbW1x4cIFnXkWFhZVW/jKYpgSERkMRcP0gw8+wJgxYzB27FgAwNKlS7Fnzx6sWrUKERERxa7XsGFD2NvbF/u9SqWCi4tLVRe3arGZl4jIYCjWzJuTk4O4uDgEBwfrzA8ODkZsbGyJ63bs2BGurq7o2bMnDh48WOj7O3fuwNPTE40aNUK/fv1w6tSpEreXnZ0NtVqtM1U3kcaaKRGRoVAsTFNTU6HRaODs7Kwz39nZGcnJyUWu4+rqitWrVyMqKgrfffcdWrVqhZ49e+LIkSPaZVq3bo3169cjOjoamzdvhoWFBbp06YKLFy8WW5aIiAjY2dlpJw8Pj6o5yBLcSb2PHJgDYJgSEdV2KiGEUGLHN2/ehLu7O2JjYxEYGKid//bbb2Pjxo06nYpK0r9/f6hUKkRHRxf5fV5eHjp16oRu3brho48+KnKZ7OxsZGdnaz+r1Wp4eHggIyND59psVbrSoDOapf4CS4s83MtSvB8YEREVQa1Ww87OrtQ8UOyvuJOTE4yNjQvVQlNSUgrVVksSEBBQYq3TyMgIfn5+JS5jbm4OW1tbnalaCYHU28YAAKf6edW7LyIiqnaKhamZmRl8fHwQExOjMz8mJgZBQUFl3s6pU6fg6upa7PdCCMTHx5e4jN7dvYtUjT0ADnJPRGQIFO3NO2XKFISFhcHX1xeBgYFYvXo1EhISEB4eDgCYMWMGEhMTsWHDBgCyt2+TJk3Qtm1b5OTk4Msvv0RUVBSioqK025w/fz4CAgLQokULqNVqfPTRR4iPj8eKFSsUOcYiFezJ25BNvEREtZ2iYRoaGoq0tDQsWLAASUlJaNeuHXbu3AlPT08AQFJSEhISErTL5+Tk4I033kBiYiIsLS3Rtm1b7NixA3379tUuk56ejpdffhnJycmws7NDx44dceTIEXTu3Fnvx1csPjGGiMigKNYBqSYr6wXnCtu/H7Oe/gnvYBYmTACK6RdFREQKq/EdkOo0DthARGRQGKZK4FCCREQGhWGqBIYpEZFBYZgqgc28REQGhWGqBNZMiYgMCsNUAXlpt5EGRwAMUyIiQ8AwVUBGSjY0/97i6+iocGGIiKjSGKYKSE2Vrzb1cmFurmxZiIio8himCki9JX92JweNwiUhIqKqwDDVNyGQmmEKgEMJEhEZCoapvt25g9Q8BwCAk7OxwoUhIqKqwDDVt4K3xTjz5yciMgT8a65vOgM2sJmXiMgQMEz1jQM2EBEZHIapvjFMiYgMDsNU3zguLxGRwWGY6htrpkREBodhqm8MUyIig8Mw1bPcf27jNv69z5RhSkRkEBimenb77xyIf3/2+vUVLgwREVUJhqmepf4jAAAO1jkwMVG4MEREVCUYpnqWmiYHanCyz1W4JEREVFUYpnqWmiGro06OQuGSEBFRVWGY6pMQSM20AAA4NeBPT0RkKPgXXZ8yMx8+McbVVOHCEBFRVWGY6lPBe0xd2PuIiMhQMEz1iQM2EBEZJIapPnFcXiIig8Qw1SfWTImIDBLDVJ8YpkREBolhqk9s5iUiMkgMUz3K+ScDatgBYJgSERkShqkepSXlAACMVHmwt1e2LEREVHUYpnqU+rcGAOBonQ0j/vJERAaDf9L1SDvIvd0DhUtCRERViWGqR6m3jQEATvXzFC4JERFVJYapHqWqzQAATg1UCpeEiIiqkuJhunLlSjRt2hQWFhbw8fHB0aNHi1320KFDUKlUhabz58/rLBcVFYU2bdrA3Nwcbdq0wdatW6v7MEonBFLvWgIAnJw5Li8RkSFRNEy3bNmCyZMnY9asWTh16hS6du2KkJAQJCQklLjehQsXkJSUpJ1atGih/e748eMIDQ1FWFgYfvvtN4SFhWHIkCH4+eefq/twSpaZiVRRHwDg5GambFmIiKhKqYQQij2l2t/fH506dcKqVau087y8vDBo0CBEREQUWv7QoUN48skncfv2bdgXc29JaGgo1Go1du3apZ3Xp08fODg4YPPmzWUql1qthp2dHTIyMmBra1u+gyrOlSsY3iwWmzAc778PTJlSNZslIqLqU9Y8UKxmmpOTg7i4OAQHB+vMDw4ORmxsbInrduzYEa6urujZsycOHjyo893x48cLbbN3794lbjM7OxtqtVpnqnIcSpCIyGApFqapqanQaDRwdnbWme/s7Izk5OQi13F1dcXq1asRFRWF7777Dq1atULPnj1x5MgR7TLJycnl2iYAREREwM7OTjt5eHhU4siKwTAlIjJYiveEUal0e7YKIQrNy9eqVSu0atVK+zkwMBDXr1/He++9h27dulVomwAwY8YMTCnQ7qpWq6s+UNPSkIqWABimRESGRrGaqZOTE4yNjQvVGFNSUgrVLEsSEBCAixcvaj+7uLiUe5vm5uawtbXVmaoca6ZERAZLsTA1MzODj48PYmJidObHxMQgKCiozNs5deoUXF1dtZ8DAwMLbXPv3r3l2mZ1uJesxj1YAWCYEhEZGkWbeadMmYKwsDD4+voiMDAQq1evRkJCAsLDwwHI5tfExERs2LABALB06VI0adIEbdu2RU5ODr788ktERUUhKipKu81JkyahW7duWLx4MQYOHIjt27dj3759OHbsmCLHmC/tZjYAwNQoFzY2ireuExFRFVL0r3poaCjS0tKwYMECJCUloV27dti5cyc8PT0BAElJSTr3nObk5OCNN95AYmIiLC0t0bZtW+zYsQN9+/bVLhMUFITIyEi8+eabmD17Npo3b44tW7bA399f78dXUGpyLgDAyeo+VCprRctCRERVS9H7TGuq6rjPNMb/TQT/shDt3W/h9I36VbJNIiKqXjX+PtO6RjvIvYNG4ZIQEVFVY5jqSWqGKQDAyYkNAUREhoZhqiepmeYAACdnY4VLQkREVY1hqg95eUjN+ve2GFcOck9EZGgYpvqQmYlUOAIAnBpZKFwYIiKqagxTfUhLezj6kaupwoUhIqKqxjDVBw4lSERk0Bim+sAwJSIyaAxTPRCpaQxTIiIDxjDVgztJmcjBv7fGMEyJiAwOw1QPUhPlIPeWxjmoV0/hwhARUZVjmOpB6s0cAICT1T2FS0JERNWBYaoHqf/IIQSdrLMVLgkREVUHhqkepKapAABO9rkKl4SIiKoDw1QPUtPlY2OdHPMULgkREVUHhqkepGbK8XidGvDnJiIyRPzrrgep92QXXicXE4VLQkRE1YFhWt3y8pB63wYA0MCDg9wTERkihml1U6sfPjHGw1LhwhARUXVgmFa3guPyuvFZpkREhohhWt3SOC4vEZGhY5hWs7zUW0jLb+ZlmBIRGSSGaTXLuJEJDWQvXkdHhQtDRETVgmFazVKvZwEAbE3uwYyXTImIDBLDtJqlJj0AADhZ3lW4JEREVF0YptUs9W8NAMDJ+r7CJSEiourCMK1mqan/PjHG7oHCJSEiourCMK1mqbeNAQBO9TUKl4SIiKoLw7SapWb8O8i9k0rhkhARUXVhmFaz1LtyPF4nF2OFS0JERNWFYVrNUrOsAQBObuYKl4SIiKoLw7Q65eUh9YEtAMCJT4whIjJYDNPqlJHxcFxeT2uFC0NERNWFYVqd+MQYIqI6gWFajXJTbuE2HABwkHsiIkPGMK1Gt6+pIWAEFfLg4KB0aYiIqLooHqYrV65E06ZNYWFhAR8fHxw9erRM6/34448wMTFBhw4ddOavX78eKpWq0HT/vv6H88sf5N7B5A5MTPS+eyIi0hNFw3TLli2YPHkyZs2ahVOnTqFr164ICQlBQkJCietlZGRgxIgR6NmzZ5Hf29raIikpSWeysNB/b9rUxGwAgJPFHb3vm4iI9EfRMP3ggw8wZswYjB07Fl5eXli6dCk8PDywatWqEtd75ZVX8OKLLyIwMLDI71UqFVxcXHQmJaQm5wIAnKyyFNk/ERHph2JhmpOTg7i4OAQHB+vMDw4ORmxsbLHrrVu3DpcuXcLcuXOLXebOnTvw9PREo0aN0K9fP5w6darEsmRnZ0OtVutMVSH1n38HubfNrpLtERFRzaRYmKampkKj0cDZ2VlnvrOzM5KTk4tc5+LFi5g+fTq++uormBRzEbJ169ZYv349oqOjsXnzZlhYWKBLly64ePFisWWJiIiAnZ2ddvLw8Kj4gRWQekv+vE72HOSeiMiQKd4BSaXSHQBeCFFoHgBoNBq8+OKLmD9/Plq2bFns9gICAvB///d/8Pb2RteuXfH111+jZcuWWL58ebHrzJgxAxkZGdrp+vXrFT+gAlLTZeDzthgiIsOmWB9TJycnGBsbF6qFpqSkFKqtAkBmZiZOnjyJU6dOYfz48QCAvLw8CCFgYmKCvXv34qmnniq0npGREfz8/EqsmZqbm8PcvOrHzk29I7fp1FDxf7MQEVE1UuyvvJmZGXx8fBATE6MzPyYmBkFBQYWWt7W1xZkzZxAfH6+dwsPD0apVK8THx8Pf37/I/QghEB8fD1dX12o5jpKk3rMCADi5mup930REpD+K3v04ZcoUhIWFwdfXF4GBgVi9ejUSEhIQHh4OQDa/JiYmYsOGDTAyMkK7du101m/YsCEsLCx05s+fPx8BAQFo0aIF1Go1PvroI8THx2PFihV6PTYASM22AQA4NeIg90REhkzRMA0NDUVaWhoWLFiApKQktGvXDjt37oSnpycAICkpqdR7Th+Vnp6Ol19+GcnJybCzs0PHjh1x5MgRdO7cuToOoXh5eUjV2AMAnDyt9LtvIiLSK5UQQihdiJpGrVbDzs4OGRkZsLW1rdhGbt+GXX0jqGGHP3/PQYu2HOieiKi2KWsesGdMNclJSoMadgD4xBgiIkPHMK0maenGAABjlQZ2dgoXhoiIqhXDtJqk2jQFADg2MIYRf2UiIoPGZ5lUk2bNgKNHAQUeVkNERHrGMK0mVlbAE08oXQoiItIHNkASERFVEsOUiIiokhimRERElcQwJSIiqiSGKRERUSUxTImIiCqJYUpERFRJDFMiIqJKYpgSERFVEsOUiIiokhimRERElcQwJSIiqiSGKRERUSUxTImIiCqJj2ArghACAKBWqxUuCRERKSk/B/JzoTgM0yJkZmYCADw8PBQuCRER1QSZmZmws7Mr9nuVKC1u66C8vDzcvHkTNjY2UKlU2vlqtRoeHh64fv06bG1tFSyhftS14wV4zDxmw1TXjheoumMWQiAzMxNubm4wMir+yihrpkUwMjJCo0aNiv3e1ta2zvwHCdS94wV4zHVFXTvmuna8QNUcc0k10nzsgERERFRJDFMiIqJKYpiWg7m5OebOnQtzc3Oli6IXde14AR5zXVHXjrmuHS+g/2NmByQiIqJKYs2UiIiokhimRERElcQwJSIiqiSGKRERUSUxTMto5cqVaNq0KSwsLODj44OjR48qXaRqM2/ePKhUKp3JxcVF6WJVqSNHjqB///5wc3ODSqXCtm3bdL4XQmDevHlwc3ODpaUlevTogT/++EOZwlaR0o551KhRhc57QECAMoWtAhEREfDz84ONjQ0aNmyIQYMG4cKFCzrLGNp5LssxG9J5XrVqFR5//HHtwAyBgYHYtWuX9nt9nl+GaRls2bIFkydPxqxZs3Dq1Cl07doVISEhSEhIULpo1aZt27ZISkrSTmfOnFG6SFXq7t278Pb2xscff1zk90uWLMEHH3yAjz/+GCdOnICLiwt69eqlHbe5NirtmAGgT58+Oud9586deixh1Tp8+DDGjRuHn376CTExMcjNzUVwcDDu3r2rXcbQznNZjhkwnPPcqFEjLFq0CCdPnsTJkyfx1FNPYeDAgdrA1Ov5FVSqzp07i/DwcJ15rVu3FtOnT1eoRNVr7ty5wtvbW+li6A0AsXXrVu3nvLw84eLiIhYtWqSdd//+fWFnZyc++eQTBUpY9R49ZiGEGDlypBg4cKAi5dGHlJQUAUAcPnxYCFE3zvOjxyyE4Z9nBwcH8fnnn+v9/LJmWoqcnBzExcUhODhYZ35wcDBiY2MVKlX1u3jxItzc3NC0aVMMHToUly9fVrpIenPlyhUkJyfrnHNzc3N0797doM85ABw6dAgNGzZEy5Yt8Z///AcpKSlKF6nKZGRkAADq168PoG6c50ePOZ8hnmeNRoPIyEjcvXsXgYGBej+/DNNSpKamQqPRwNnZWWe+s7MzkpOTFSpV9fL398eGDRuwZ88efPbZZ0hOTkZQUBDS0tKULppe5J/XunTOASAkJARfffUVDhw4gPfffx8nTpzAU089hezsbKWLVmlCCEyZMgVPPPEE2rVrB8Dwz3NRxwwY3nk+c+YMrK2tYW5ujvDwcGzduhVt2rTR+/nlU2PKqOCj2AD5H+qj8wxFSEiI9n379u0RGBiI5s2b44svvsCUKVMULJl+1aVzDgChoaHa9+3atYOvry88PT2xY8cOPPvsswqWrPLGjx+P06dP49ixY4W+M9TzXNwxG9p5btWqFeLj45Geno6oqCiMHDkShw8f1n6vr/PLmmkpnJycYGxsXOhfMikpKYX+xWOorKys0L59e1y8eFHpouhFfs/lunzOAcDV1RWenp61/rxPmDAB0dHROHjwoM6jFQ35PBd3zEWp7efZzMwMjz32GHx9fREREQFvb28sW7ZM7+eXYVoKMzMz+Pj4ICYmRmd+TEwMgoKCFCqVfmVnZ+PcuXNwdXVVuih60bRpU7i4uOic85ycHBw+fLjOnHMASEtLw/Xr12vteRdCYPz48fjuu+9w4MABNG3aVOd7QzzPpR1zUWr7eX6UEALZ2dn6P79V3qXJAEVGRgpTU1OxZs0acfbsWTF58mRhZWUlrl69qnTRqsXUqVPFoUOHxOXLl8VPP/0k+vXrJ2xsbAzqeDMzM8WpU6fEqVOnBADxwQcfiFOnTolr164JIYRYtGiRsLOzE9999504c+aMGDZsmHB1dRVqtVrhkldcScecmZkppk6dKmJjY8WVK1fEwYMHRWBgoHB3d6+1x/zqq68KOzs7cejQIZGUlKSd7t27p13G0M5zacdsaOd5xowZ4siRI+LKlSvi9OnTYubMmcLIyEjs3btXCKHf88swLaMVK1YIT09PYWZmJjp16qTT1dzQhIaGCldXV2Fqairc3NzEs88+K/744w+li1WlDh48KAAUmkaOHCmEkLdNzJ07V7i4uAhzc3PRrVs3cebMGWULXUklHfO9e/dEcHCwaNCggTA1NRWNGzcWI0eOFAkJCUoXu8KKOlYAYt26ddplDO08l3bMhnaeR48erf273KBBA9GzZ09tkAqh3/PLR7ARERFVEq+ZEhERVRLDlIiIqJIYpkRERJXEMCUiIqokhikREVElMUyJiIgqiWFKRERUSQxTIiKiSmKYEtUCV69ehUqlQnx8vNJF0Tp//jwCAgJgYWGBDh06KF2cMjl06BBUKhXS09OVLgoZGIYpURmMGjUKKpUKixYt0pm/bds2g3hcV0XMnTsXVlZWuHDhAvbv3690cYgUxTAlKiMLCwssXrwYt2/fVrooVSYnJ6fC6166dAlPPPEEPD094ejoWO37I6rJGKZEZfT000/DxcUFERERxS4zb968Qk2eS5cuRZMmTbSfR40ahUGDBuGdd96Bs7Mz7O3tMX/+fOTm5mLatGmoX78+GjVqhLVr1xba/vnz5xEUFAQLCwu0bdsWhw4d0vn+7Nmz6Nu3L6ytreHs7IywsDCkpqZqv+/RowfGjx+PKVOmwMnJCb169SryOPLy8rBgwQI0atQI5ubm6NChA3bv3q39XqVSIS4uDgsWLIBKpcK8efOK3E5x+zt8+DA6d+4Mc3NzuLq6Yvr06cjNzdWu16RJEyxdulRnWx06dNDZj0qlwueff47BgwejXr16aNGiBaKjo3XW2blzJ1q2bAlLS0s8+eSTuHr1qs73165dQ//+/eHg4AArKyu0bdsWO3fuLPJYiErCMCUqI2NjY7zzzjtYvnw5bty4UaltHThwADdv3sSRI0fwwQcfYN68eejXrx8cHBzw888/Izw8HOHh4bh+/brOetOmTcPUqVNx6tQpBAUFYcCAAUhLSwMAJCUloXv37ujQoQNOnjyJ3bt34++//8aQIUN0tvHFF1/AxMQEP/74Iz799NMiy7ds2TK8//77eO+993D69Gn07t0bAwYM0D5AOikpCW3btsXUqVORlJSEN954o9hjfXR/iYmJ6Nu3L/z8/PDbb79h1apVWLNmDRYuXFju33H+/PkYMmQITp8+jb59+2L48OG4desWAOD69et49tln0bdvX8THx2Ps2LGYPn26zvrjxo1DdnY2jhw5gjNnzmDx4sWwtrYudzmI+Ag2ojIYOXKkGDhwoBBCiICAADF69GghhBBbt24VBf83mjt3rvD29tZZ98MPPxSenp462/L09BQajUY7r1WrVqJr167az7m5ucLKykps3rxZCCHElStXBACxaNEi7TIPHjwQjRo1EosXLxZCCDF79mwRHByss+/r168LAOLChQtCCCG6d+8uOnToUOrxurm5ibfffltnnp+fn3jttde0n729vcXcuXNL3E5R+5s5c6Zo1aqVyMvL085bsWKFsLa21v4mnp6e4sMPP9RZ79H9ARBvvvmm9vOdO3eESqUSu3btEkLIZ116eXnp7Od///ufACBu374thBCiffv2Yt68eSUeA1FZsGZKVE6LFy/GF198gbNnz1Z4G23btoWR0cP//ZydndG+fXvtZ2NjYzg6OiIlJUVnvcDAQO17ExMT+Pr64ty5cwCAuLg4HDx4ENbW1tqpdevWAOT1zXy+vr4llk2tVuPmzZvo0qWLzvwuXbpo91Uej+7v3LlzCAwM1Om41aVLF9y5c6fcNf7HH39c+97Kygo2Njba3+zcuXMICAjQ2U/B3w8AJk6ciIULF6JLly6YO3cuTp8+Xa79E+VjmBKVU7du3dC7d2/MnDmz0HdGRkYQjzwi+MGDB4WWMzU11fmsUqmKnJeXl1dqefLDIi8vD/3790d8fLzOdPHiRXTr1k27vJWVVanbLLjdfEKICvVcfnR/RW0n/zfLn1+Z3zH/N3t0/aKMHTsWly9fRlhYGM6cOQNfX18sX7681PWIHsUwJaqARYsW4fvvv0dsbKzO/AYNGiA5OVnnD3lV3hv6008/ad/n5uYiLi5OW/vs1KkT/vjjDzRp0gSPPfaYzlTWAAUAW1tbuLm54dixYzrzY2Nj4eXlVeljaNOmDWJjY3V+o9jYWNjY2MDd3R2A/B2TkpK036vValy5cqXc+yn4ewEo9BkAPDw8EB4eju+++w5Tp07FZ599Vq79EAEMU6IKad++PYYPH16oFtOjRw/8888/WLJkCS5duoQVK1Zg165dVbbfFStWYOvWrTh//jzGjRuH27dvY/To0QBkZ5pbt25h2LBh+OWXX3D58mXs3bsXo0ePhkajKdd+pk2bhsWLF2PLli24cOECpk+fjvj4eEyaNKnSx/Daa6/h+vXrmDBhAs6fP4/t27dj7ty5mDJlirbp+6mnnsLGjRtx9OhR/P777xg5ciSMjY3LtZ/w8HBcunQJU6ZMwYULF7Bp0yasX79eZ5nJkydjz549uHLlCn799VccOHCgSv7BQHUPw5Sogt56661CTYleXl5YuXIlVqxYAW9vb/zyyy8l9nQtr0WLFmHx4sXw9vbG0aNHsX37djg5OQEA3Nzc8OOPP0Kj0aB3795o164dJk2aBDs7O53rs2UxceJETJ06FVOnTkX79u2xe/duREdHo0WLFpU+Bnd3d+zcuRO//PILvL29ER4ejjFjxuDNN9/ULjNjxgx069YN/fr1Q9++fTFo0CA0b968XPtp3LgxoqKi8P3338Pb2xuffPIJ3nnnHZ1lNBoNxo0bBy8vL/Tp0wetWrXCypUrK32MVPeoRFkuLBAREVGxWDMlIiKqJIYpERFRJTFMiYiIKolhSkREVEkMUyIiokpimBIREVUSw5SIiKiSGKZERESVxDAlIiKqJIYpERFRJTFMiYiIKun/AUj9obMbYtqXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i + 1 for i in range(len(history_FL))], [history_FL[i][0] for i in range(len(history_FL))], color='r', label='train loss')\n",
    "plt.plot([i + 1 for i in range(len(history_FL))], [history_FL[i][1] for i in range(len(history_FL))], color='b', label='dev loss')\n",
    "plt.legend()\n",
    "plt.title(\"Rounds vs Accuracy\")\n",
    "plt.xlabel(\"Number of rounds\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.809299111366272, 0.7060917615890503, 29)\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(max(history_FL))\n",
    "print(traffic[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class memory:\n",
    "\n",
    "    def __init__(self, batch_number, batch_size):\n",
    "        self.batch_number = batch_number\n",
    "        self.batch_size = batch_size\n",
    "        self.matrix = np.zeros((batch_number, batch_size), dtype=int)\n",
    "        self.add_time = 0\n",
    "\n",
    "    def add_number(self, batch_no, true_array):\n",
    "        if batch_no >= self.batch_number:\n",
    "            print(f\"Warning: Batch number {batch_no} out of range. Skipping this entry.\")\n",
    "            return\n",
    "        # Ensure true_array length matches batch_size by padding or truncating as necessary\n",
    "        true_array = np.pad(true_array, (0, max(0, self.batch_size - len(true_array))), mode='constant')[:self.batch_size]\n",
    "        self.matrix[batch_no] += true_array\n",
    "\n",
    "\n",
    "    def add(self):\n",
    "        self.add_time = self.add_time + 1\n",
    "\n",
    "    def get_ambiguous(self, number):\n",
    "        temp_matrix = self.matrix\n",
    "        temp_matrix = np.abs(temp_matrix - np.ones(self.matrix.shape) * self.add_time * 0.5)\n",
    "        temp_array = np.reshape(temp_matrix, self.matrix.shape[0] * self.matrix.shape[1])\n",
    "        temp = list(map(list, zip(range(len(temp_array)), temp_array)))\n",
    "        small = sorted(temp, key=lambda x: x[1], reverse=False)\n",
    "        small_array = []\n",
    "        for i in range(number):\n",
    "            small_array.append(small[i][0])\n",
    "        return small_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "# import dnn_model  # Assumed custom DNN model import\n",
    "# from memory import memory  # Assumed memory module import\n",
    "\n",
    "\n",
    "class KMT:\n",
    "    learning_rate = 0.01\n",
    "    momentum = 0.5\n",
    "    batch_size = 32\n",
    "    batch_number = 1000\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    test_accuracy = []\n",
    "\n",
    "    def __init__(self, dataset, index, test_loader):\n",
    "        # Load training set and initialize test loader\n",
    "        self.load_train_set(dataset, index)\n",
    "        self.test_loader = test_loader\n",
    "        self.model = FederatedNet()  # Use FederatedNet model here\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.distillation_criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate, momentum=self.momentum)\n",
    "        self.memory = memory(self.batch_number, self.batch_size)\n",
    "\n",
    "    def load_train_set(self, dataset, index):\n",
    "        # Subset and DataLoader for training\n",
    "        train_dataset = torch.utils.data.Subset(dataset, index.astype(int))\n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def train(self):\n",
    "        # Standard training without distillation\n",
    "        self.memory.add()  # Initialize memory\n",
    "        running_loss = 0\n",
    "        batch_number = 0\n",
    "\n",
    "        for images, labels in self.train_loader:\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(images)\n",
    "            loss = self.criterion(output, labels)\n",
    "\n",
    "            # Accuracy calculation for memory tracking\n",
    "            log_ps = torch.log_softmax(output, dim=1)\n",
    "            ps = torch.exp(log_ps)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = (top_class == labels.view(*top_class.shape)).numpy().squeeze().astype(int).transpose()\n",
    "            self.memory.add_number(batch_number, equals)\n",
    "\n",
    "            # Backpropagation and optimizer step\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            batch_number += 1\n",
    "\n",
    "        self.train_loss.append(running_loss / len(self.train_loader))\n",
    "\n",
    "    def distillation_train(self, images, labels, other_soft_decision):\n",
    "        # Knowledge distillation training with soft labels from other clients\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.model(images)\n",
    "        loss1 = self.criterion(output, labels)\n",
    "        loss2 = self.distillation_criterion(torch.log_softmax(output, dim=1), other_soft_decision)\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        log_ps = torch.log_softmax(output, dim=1)\n",
    "        ps = torch.exp(log_ps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        equals = (top_class == labels.view(*top_class.shape)).numpy().squeeze().astype(int).transpose()\n",
    "\n",
    "        # Backpropagation and optimizer step\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return equals\n",
    "\n",
    "    def test(self):\n",
    "        accuracy = 0\n",
    "        loss = 0\n",
    "        for images, labels in self.test_loader:\n",
    "            output = self.model(images)\n",
    "            log_ps = torch.log_softmax(output, dim=1)\n",
    "            ps = torch.exp(log_ps)\n",
    "            loss += self.criterion(log_ps, labels)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        self.test_loss.append((loss / len(self.test_loader)).item())\n",
    "        self.test_accuracy.append((accuracy / len(self.test_loader)).item())\n",
    "        return accuracy / len(self.test_loader)\n",
    "\n",
    "    def save_model(self, filename=\"temp_model.pt\"):\n",
    "        torch.save(self.model.state_dict(), filename)\n",
    "\n",
    "    def load_model(self, filename=\"temp_model.pt\"):\n",
    "        self.model.load_state_dict(torch.load(filename))\n",
    "\n",
    "    def get_ambiguous_data(self, array):\n",
    "        np.sort(array)\n",
    "        batch_number = 0\n",
    "        ambiguous_images = []\n",
    "        ambiguous_labels = []\n",
    "        for images, labels in self.train_loader:\n",
    "            for no in array:\n",
    "                if int(no / self.batch_size) == batch_number:\n",
    "                    column = np.mod(no, self.batch_size)\n",
    "                    ambiguous_images.append(images[column])\n",
    "                    ambiguous_labels.append(labels[column])\n",
    "            batch_number += 1\n",
    "        ambiguous_images = torch.stack(ambiguous_images)\n",
    "        ambiguous_labels = torch.stack(ambiguous_labels)\n",
    "        return ambiguous_images, ambiguous_labels\n",
    "\n",
    "    def test_data(self, images, labels):\n",
    "        loss = 0\n",
    "        output = self.model(images)\n",
    "        log_ps = torch.log_softmax(output, dim=1)\n",
    "        loss += self.criterion(log_ps, labels)\n",
    "        return loss\n",
    "\n",
    "    def test_data_accuracy(self, images, labels):\n",
    "        output = self.model(images)\n",
    "        log_ps = torch.log_softmax(output, dim=1)\n",
    "        ps = torch.exp(log_ps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, client_id, dataset, test_loader):\n",
    "        self.client_id = client_id\n",
    "        self.dataset = dataset\n",
    "        # self.test_loader = test_loader\n",
    "        self.kmt = KMT(dataset, index=np.arange(len(dataset)), test_loader=test_loader)\n",
    "        self.client_data = []\n",
    "\n",
    "    def get_dataset_size(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def get_client_id(self):\n",
    "        return self.client_id\n",
    "\n",
    "    def train(self, parameters_dict, other_soft_decisions=None):\n",
    "        # Load initial parameters\n",
    "        self.kmt.model.load_state_dict(parameters_dict)\n",
    "\n",
    "        # Standard training\n",
    "        self.kmt.train()\n",
    "\n",
    "        # Knowledge distillation using soft labels from other clients (if available)\n",
    "        if other_soft_decisions is not None:\n",
    "            for images, labels in self.kmt.train_loader:\n",
    "                if images in other_soft_decisions:\n",
    "                    other_soft_decision = other_soft_decisions[images]\n",
    "                    self.kmt.distillation_train(images, labels, other_soft_decision)\n",
    "        \n",
    "        # Return the updated model parameters\n",
    "        return self.kmt.model.state_dict()\n",
    "\n",
    "    def recieve_parameters(self, client_id, client_parameter, fraction):\n",
    "        client_object = {\"client_id\": client_id, \"client_parameter\": client_parameter, \"fraction\": fraction}\n",
    "        self.client_data.append(client_object)\n",
    "\n",
    "    def aggregated_parameters(self):\n",
    "        local_aggregated_model = None\n",
    "        for i in range(len(self.client_data)):\n",
    "            local_aggregated_model = average_models(local_aggregated_model, self.client_data[i][\"client_parameter\"], self.client_data[i][\"fraction\"])\n",
    "        self.client_data.clear()\n",
    "        return local_aggregated_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=200, shuffle=True)\n",
    "clients = [Client(i, client_datasets[i], test_loader) for i in range(num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After round 1, train_loss = 1.6111, dev_loss = 1.6036, dev_acc = 0.4273\n",
      "After round 2, train_loss = 1.5523, dev_loss = 1.5705, dev_acc = 0.4893\n",
      "After round 3, train_loss = 1.3589, dev_loss = 1.4021, dev_acc = 0.5342\n"
     ]
    }
   ],
   "source": [
    "dfl_start_time = time.time()\n",
    "\n",
    "global_net = to_device(FederatedNet(), device)\n",
    "curr_parameters = global_net.state_dict()\n",
    "history_dfl = []\n",
    "weights = []\n",
    "traffic = []\n",
    "load_model = None\n",
    "total_data_size = len(train_dataset)\n",
    "\n",
    "for i in range(rounds):\n",
    "    new_model = None\n",
    "    soft_decisions = {}  # Dictionary to store each client's soft decisions for distillation\n",
    "\n",
    "    # Step 1: Each client performs training and generates soft decisions\n",
    "    for client in clients:\n",
    "        fraction = client.get_dataset_size() / total_data_size\n",
    "\n",
    "        if i == 0:\n",
    "            # Each client trains on its dataset, possibly using other clients' soft decisions for distillation\n",
    "            client_parameters = client.train(curr_parameters, other_soft_decisions=soft_decisions if i > 0 else None)\n",
    "        else:\n",
    "            # Each client trains on its dataset, possibly using other clients' soft decisions for distillation\n",
    "            client_parameters = client.train(client.aggregated_parameters(), other_soft_decisions=soft_decisions)\n",
    "        \n",
    "        # Gather soft decisions for this client's data to use in distillation\n",
    "        for images, labels in client.kmt.train_loader:\n",
    "            output = client.kmt.model(images)\n",
    "            soft_decisions[images] = torch.softmax(output, dim=1).detach()\n",
    "\n",
    "        # Share parameters with other clients for aggregation\n",
    "        for clt in clients:\n",
    "            clt.recieve_parameters(client.get_client_id(), client_parameters, fraction)\n",
    "\n",
    "        # Aggregate models across all clients\n",
    "        new_model = average_models(new_model, client_parameters, fraction)\n",
    "\n",
    "    # Update the global model and evaluate\n",
    "    load_model = new_model.copy()\n",
    "    global_net.load_state_dict(new_model)\n",
    "    train_loss, train_acc = global_net.evaluate(train_dataset)\n",
    "    dev_loss, dev_acc = global_net.evaluate(test_dataset)\n",
    "    \n",
    "    # Logging\n",
    "    print(f'After round {i + 1}, train_loss = {round(train_loss, 4)}, dev_loss = {round(dev_loss, 4)}, dev_acc = {round(dev_acc, 4)}')\n",
    "    history_dfl.append((train_acc, dev_acc, i))\n",
    "    traffic.append((num_clients) * (num_clients - 1))\n",
    "\n",
    "# Calculate total time\n",
    "dfl_end_time = time.time()\n",
    "dfl_time = dfl_end_time - dfl_start_time\n",
    "print(f\"Total training time: {dfl_time:.2f} seconds\")\n",
    "\n",
    "# Optionally save the final global model if needed\n",
    "torch.save(global_net.state_dict(), \"final_global_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i + 1 for i in range(len(history_dfl))], [history_dfl[i][0] for i in range(len(history_dfl))], color='r', label='train accuracy')\n",
    "plt.plot([i + 1 for i in range(len(history_dfl))], [history_dfl[i][1] for i in range(len(history_dfl))], color='b', label='dev accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Rounds vs Accuracy\")\n",
    "plt.xlabel(\"Number of rounds\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, client_id, dataset, test_loader):\n",
    "        self.client_id = client_id\n",
    "        self.dataset = dataset\n",
    "        self.kmt = KMT(dataset, index=np.arange(len(dataset)), test_loader=test_loader)\n",
    "        self.client_data=[]\n",
    "        self.server_id=-1\n",
    "        self.distance=random.randint(1,100)\n",
    "\n",
    "    def set_server_id(self,client_id):\n",
    "        self.client_data_server=[]\n",
    "        self.server_id=client_id\n",
    "    \n",
    "    def get_server_id(self):\n",
    "        return self.server_id\n",
    "\n",
    "    def get_dataset_size(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def get_client_id(self):\n",
    "        return self.client_id\n",
    "\n",
    "    def train(self, parameters_dict, other_soft_decisions=None):\n",
    "        # Load initial parameters\n",
    "        self.kmt.model.load_state_dict(parameters_dict)\n",
    "\n",
    "        # Standard training\n",
    "        self.kmt.train()\n",
    "\n",
    "        # Knowledge distillation using soft labels from other clients (if available)\n",
    "        if other_soft_decisions is not None:\n",
    "            for images, labels in self.kmt.train_loader:\n",
    "                if images in other_soft_decisions:\n",
    "                    other_soft_decision = other_soft_decisions[images]\n",
    "                    self.kmt.distillation_train(images, labels, other_soft_decision)\n",
    "        \n",
    "        # Return the updated model parameters\n",
    "        return self.kmt.model.state_dict()\n",
    "\n",
    "    def recieve_parameters(self, client_id, client_parameter, fraction):\n",
    "        client_object = {\"client_id\": client_id, \"client_parameter\": client_parameter, \"fraction\": fraction}\n",
    "        self.client_data.append(client_object)\n",
    "\n",
    "    def aggregated_parameters(self):\n",
    "        local_aggregated_model = None\n",
    "        for i in range(len(self.client_data)):\n",
    "            local_aggregated_model = average_models(local_aggregated_model, self.client_data[i][\"client_parameter\"], self.client_data[i][\"fraction\"])\n",
    "        self.client_data.clear()\n",
    "        return local_aggregated_model\n",
    "    \n",
    "    def recieve_data_as_server(self,client_parameter,fraction):\n",
    "        client_object={\"client_parameter\":client_parameter,\"fraction\":fraction}\n",
    "        self.client_data_server.append(client_object)\n",
    "    \n",
    "\n",
    "    def aggregate_parameter_as_server(self):\n",
    "         local_aggregated_model_as_server=None\n",
    "         for data in self.client_data_server:\n",
    "              local_aggregated_model_as_server=average_models(local_aggregated_model_as_server,data[\"client_parameter\"],data[\"fraction\"])\n",
    "         self.client_data_server.clear()\n",
    "         return local_aggregated_model_as_server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_function(client_set_1,client_set_2,data):\n",
    "  client_set_1_average=None\n",
    "  client_set_2_average=None\n",
    "  for i in client_set_1:\n",
    "    client_set_1_average=average_models(client_set_1_average,data[i],1)\n",
    "  for i in client_set_2:\n",
    "    client_set_2_average=average_models(client_set_2_average,data[i],1)\n",
    "  model1_weights = []\n",
    "  model2_weights = []\n",
    "  for key, value in client_set_1_average.items():\n",
    "      model1_weights.append(value.detach().cpu())\n",
    "\n",
    "  for key, value in client_set_2_average.items():\n",
    "      model2_weights.append(value.detach().cpu())\n",
    "  weight1_flat = torch.cat([param.view(-1) for param in model1_weights])\n",
    "  weight2_flat = torch.cat([param.view(-1) for param in model2_weights])\n",
    "  cosine_sim = torch.nn.functional.cosine_similarity(weight1_flat, weight2_flat, dim=0)\n",
    "  dissimilarity_score = 1 - cosine_sim.item()\n",
    "  return dissimilarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateGroupsGame(data,num_clients):\n",
    "    groups=[]\n",
    "    for i in range(0,num_clients):\n",
    "        groups.append([i])\n",
    "    while True:\n",
    "        for group in groups:\n",
    "            for x in group:\n",
    "                no_change_flag=0\n",
    "                max_group=None\n",
    "                max_utility=0\n",
    "                for g in groups:\n",
    "                    if g!=group:\n",
    "                        if len(g) >= 1 and len(group) > 1:\n",
    "                            tempset_1=g.copy()\n",
    "                            tempset_1.append(x)\n",
    "                            tempset_2=group.copy()\n",
    "                            tempset_2.remove(x)\n",
    "                            if utility_function(tempset_1,tempset_2,data) > utility_function(g,group,data): \n",
    "                                if max_utility < utility_function(tempset_1,tempset_2,data):\n",
    "                                    max_group=g\n",
    "                                    max_utility=utility_function(tempset_1,tempset_2,data)        \n",
    "                        elif len(group)<=1:\n",
    "                            if utility_function(g,group,data) > max_utility:\n",
    "                                max_group=g\n",
    "                                max_utility=utility_function(g,group,data)\n",
    "                if max_group is not None:  \n",
    "                    group.remove(x)\n",
    "                    max_group.append(x)\n",
    "                    no_change_flag=1\n",
    "                    if len(group) <=0 :\n",
    "                        groups.remove(group)\n",
    "        if no_change_flag == 0:\n",
    "            break\n",
    "    print(\"end\")\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupDataLength(groups,clients):\n",
    "    group_dataset_length=[]\n",
    "    for grp in groups:\n",
    "        totalcount=0\n",
    "        for clt in grp:\n",
    "            totalcount+=clients[clt].get_dataset_size()\n",
    "        group_dataset_length.append(totalcount)\n",
    "    return group_dataset_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=200, shuffle=True)\n",
    "clients = [Client(i, client_datasets[i], test_loader) for i in range(num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_net = to_device(FederatedNet(), device)\n",
    "curr_parameters = global_net.state_dict()\n",
    "data = []\n",
    "for client in clients:\n",
    "    paramerter=client.train(curr_parameters)\n",
    "    data.append(paramerter)\n",
    "\n",
    "groups=generateGroupsGame(data,num_clients)\n",
    "print(groups)\n",
    "group_dataset_length=groupDataLength(groups,clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfl_start_time  =time.time()\n",
    "\n",
    "# Initializing the global model and key variables\n",
    "global_net = to_device(FederatedNet(), device)\n",
    "curr_parameters = global_net.state_dict()\n",
    "history_hdfl = []\n",
    "weights = []\n",
    "traffic = []\n",
    "load_model = None\n",
    "total_dataset_length = len(train_dataset)\n",
    "flag = True\n",
    "\n",
    "# Training across rounds\n",
    "for i in range(rounds):\n",
    "\n",
    "    traffic_single_sum = 0\n",
    "    server = []\n",
    "    \n",
    "    # Step 1: Choose a random server from each group for group-level aggregation\n",
    "    for grp in groups:\n",
    "        traffic_single_sum += len(grp) - 1\n",
    "        server_id = np.random.choice(grp, p=np.ones(len(grp)) / len(grp))\n",
    "        server.append(server_id)\n",
    "        clients[server_id].set_server_id(server_id)\n",
    "    \n",
    "    k = 0  # Group index tracker\n",
    "    \n",
    "    # In-group mesh decentralized learning\n",
    "    for grp in groups:\n",
    "        flag = True\n",
    "        for j in range(in_group_rounds):\n",
    "            traffic_single_sum += (len(grp) - 1) * len(grp)\n",
    "\n",
    "            soft_decisions = {}  # Dictionary to store each client's soft decisions for distillation\n",
    "            \n",
    "            for clt in grp:\n",
    "                fraction = clients[clt].get_dataset_size() / group_dataset_length[k]\n",
    "                \n",
    "                # Train using the previous aggregated parameters or the current round model\n",
    "                if i == 0 and flag:\n",
    "                    client_parameters = clients[clt].train(curr_parameters, other_soft_decisions=soft_decisions if j > 0 else None)\n",
    "                elif j == 0:\n",
    "                    client_parameters = clients[clt].train(load_model, other_soft_decisions=soft_decisions if j > 0 else None)\n",
    "                else:\n",
    "                    client_parameters = clients[clt].train(clients[clt].aggregated_parameters(), other_soft_decisions=soft_decisions if j > 0 else None)\n",
    "                \n",
    "                # Generate and store soft decisions for knowledge distillation\n",
    "                soft_decisions = {}\n",
    "                for images, labels in clients[clt].kmt.train_loader:\n",
    "                    output = clients[clt].kmt.model(images)\n",
    "                    soft_decisions[images] = torch.softmax(output, dim=1).detach()\n",
    "                \n",
    "                # Share soft decisions and parameters with group members\n",
    "                for clt_1 in grp:\n",
    "                    clients[clt_1].recieve_parameters(clt_1, client_parameters, fraction)\n",
    "                    # clients[clt_1].kmt.update_soft_decisions(soft_decisions)\n",
    "            \n",
    "            flag = False\n",
    "        \n",
    "        # Aggregating on the chosen group server\n",
    "        for clt in grp:\n",
    "            fraction = clients[clt].get_dataset_size() / group_dataset_length[k]\n",
    "            group_params = clients[clt].aggregated_parameters()\n",
    "            clients[server[k]].recieve_data_as_server(group_params, fraction)\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    # Step 2: Inter-group aggregation across group servers\n",
    "    aggregateds = []\n",
    "    for clt in server:\n",
    "        aggregated_params = clients[clt].aggregate_parameter_as_server()\n",
    "        aggregateds.append(aggregated_params)\n",
    "    \n",
    "    # Choose a central server among group servers for top-level aggregation\n",
    "    server_id = np.random.choice(server, p=np.ones(len(server)) / len(server))\n",
    "    clients[server_id].set_server_id(server_id)\n",
    "    traffic_single_sum += len(server)\n",
    "    \n",
    "    # Aggregate parameters at the top-level server and share with the main server\n",
    "    group_number = 0\n",
    "    for clt in aggregateds:\n",
    "        fraction = group_dataset_length[group_number] / total_dataset_length\n",
    "        group_number += 1\n",
    "        clients[server_id].recieve_data_as_server(clt, fraction)\n",
    "    \n",
    "    # Top-level aggregation on the main server\n",
    "    traffic_single_sum += num_clients\n",
    "    aggregated_parameters_top = clients[server_id].aggregate_parameter_as_server()\n",
    "    load_model = aggregated_parameters_top.copy()\n",
    "    \n",
    "    # Log weights and update the global model\n",
    "    total_norm = sum(torch.norm(value.view(-1)).item() for value in load_model.values())\n",
    "    weights.append(total_norm)\n",
    "    global_net.load_state_dict(load_model)\n",
    "    \n",
    "    # Evaluation after each round\n",
    "    train_loss, train_acc = global_net.evaluate(train_dataset)\n",
    "    dev_loss, dev_acc = global_net.evaluate(test_dataset)\n",
    "    print(f'After round {i + 1}, train_loss = {round(train_loss, 4)}, dev_loss = {round(dev_loss, 4)}, dev_acc = {round(dev_acc, 4)}')\n",
    "    \n",
    "    traffic.append(traffic_single_sum)\n",
    "    history_hdfl.append((train_acc, dev_acc, i))\n",
    "\n",
    "# Calculate total time\n",
    "hdfl_end_time = time.time()\n",
    "hdfl_time = hdfl_end_time - hdfl_start_time\n",
    "print(f\"Total training time: {hdfl_time:.2f} seconds\")\n",
    "\n",
    "# Save the final model if needed\n",
    "torch.save(global_net.state_dict(), \"final_global_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i + 1 for i in range(len(history_hdfl))], [history_hdfl[i][0] for i in range(len(history_hdfl))], color='r', label='train accuracy')\n",
    "plt.plot([i + 1 for i in range(len(history_hdfl))], [history_hdfl[i][1] for i in range(len(history_hdfl))], color='b', label='dev accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Rounds vs Accuracy\")\n",
    "plt.xlabel(\"Number of rounds\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i + 1 for i in range(len(history_FL))], [history_FL[i][1] for i in range(len(history_FL))], color='r', label='FL dev accuracy')\n",
    "plt.plot([i + 1 for i in range(len(history_dfl))], [history_dfl[i][1] for i in range(len(history_dfl))], color='b', label='DFL dev accuracy')\n",
    "plt.plot([i + 1 for i in range(len(history_hdfl))], [history_hdfl[i][1] for i in range(len(history_hdfl))], color='g', label='HDFL dev accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Rounds vs Accuracy on CIFAR10\")\n",
    "plt.xlabel(\"Number of rounds\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['DFL', 'HDFL']\n",
    "values = [dfl_time, hdfl_time]\n",
    "\n",
    "# Plot the bar graph\n",
    "plt.bar(labels, values, color=['green', 'red'])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('')\n",
    "plt.ylabel('RUN TIME')\n",
    "plt.title('Run Time for DFL & HDFL')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
